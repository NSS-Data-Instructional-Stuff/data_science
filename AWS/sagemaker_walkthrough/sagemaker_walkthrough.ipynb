{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sagemaker Walkthrough\n",
    "\n",
    "In this notebook, we will go through the steps of training and deploying a model using AWS Sagemaker.\n",
    "\n",
    "We will be using the [sagemaker-python-sdk](https://github.com/aws/sagemaker-python-sdk) module throughout this notebook. \n",
    "\n",
    "We will use two different types of models for our predictions, a model built using scikit-learn, and one using an implementation of XGBoost available from sagemaker, including performing hyperparameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Initial Setup\n",
    "\n",
    "First, let's bring our data over. It is the familiar King County Housing dataset, and is currently sitting in an s3 bucket with path *s3://nss-ds3/datasets/kc_house_data.csv*\n",
    "\n",
    "Let's use the *boto3* library to fetch our data. We'll do some tricks and read it directly to a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3')\n",
    "obj = s3.get_object(Bucket='nss-ds3', Key='datasets/kc_house_data.csv')\n",
    "housing = pd.read_csv(io.BytesIO(obj['Body'].read()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>...</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7129300520</td>\n",
       "      <td>20141013T000000</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6414100192</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5631500400</td>\n",
       "      <td>20150225T000000</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2487200875</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>910</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954400510</td>\n",
       "      <td>20150218T000000</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id             date     price  bedrooms  bathrooms  sqft_living  \\\n",
       "0  7129300520  20141013T000000  221900.0         3       1.00         1180   \n",
       "1  6414100192  20141209T000000  538000.0         3       2.25         2570   \n",
       "2  5631500400  20150225T000000  180000.0         2       1.00          770   \n",
       "3  2487200875  20141209T000000  604000.0         4       3.00         1960   \n",
       "4  1954400510  20150218T000000  510000.0         3       2.00         1680   \n",
       "\n",
       "   sqft_lot  floors  waterfront  view  ...  grade  sqft_above  sqft_basement  \\\n",
       "0      5650     1.0           0     0  ...      7        1180              0   \n",
       "1      7242     2.0           0     0  ...      7        2170            400   \n",
       "2     10000     1.0           0     0  ...      6         770              0   \n",
       "3      5000     1.0           0     0  ...      7        1050            910   \n",
       "4      8080     1.0           0     0  ...      8        1680              0   \n",
       "\n",
       "   yr_built  yr_renovated  zipcode      lat     long  sqft_living15  \\\n",
       "0      1955             0    98178  47.5112 -122.257           1340   \n",
       "1      1951          1991    98125  47.7210 -122.319           1690   \n",
       "2      1933             0    98028  47.7379 -122.233           2720   \n",
       "3      1965             0    98136  47.5208 -122.393           1360   \n",
       "4      1987             0    98074  47.6168 -122.045           1800   \n",
       "\n",
       "   sqft_lot15  \n",
       "0        5650  \n",
       "1        7639  \n",
       "2        8062  \n",
       "3        5000  \n",
       "4        7503  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our data, we need to set create a sagemaker session and get our execution role. We will need to pass these as arguments when we create our models later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S3 prefix\n",
    "prefix = 'sagemaker_example'\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "# Get a SageMaker-compatible role used by this Notebook Instance.\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Data for Modeling\n",
    "\n",
    "We'll do some minor preprocessing of our data and then export the results to a csv. Notice that we will put the column we want to predict at the front, because this is what the XGBoost model will expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.zipcode = housing.zipcode.astype('category')\n",
    "\n",
    "housing = pd.get_dummies(housing[['price', 'bedrooms', 'bathrooms', 'sqft_living',\n",
    "       'sqft_lot', 'floors', 'waterfront', 'view', 'condition', 'grade',\n",
    "       'sqft_above', 'sqft_basement', 'zipcode',\n",
    "       'lat', 'long', 'sqft_living15', 'sqft_lot15']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(housing, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs('./data', exist_ok=True)\n",
    "train.to_csv('data/train.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are going to put our training data into the s3 bucket for our sagemaker instance. The following cell will take the contents of the data folder (currently our train.csv) and copy them over to a folder sm-housing/data in s3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'sm-housing'\n",
    "\n",
    "WORK_DIRECTORY = 'data'\n",
    "\n",
    "train_input = sagemaker_session.upload_data(WORK_DIRECTORY, key_prefix=\"{}/{}\".format(prefix, WORK_DIRECTORY) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are going to fit our scikit-learn model. For this to work, we need to upload the training script to our notebook instance, as the SKLearn class will be looking for it to use as an entry point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "\n",
    "script_path = 'housing_script_rf.py'\n",
    "\n",
    "sklearn = SKLearn(\n",
    "    entry_point=script_path,\n",
    "    train_instance_type=\"ml.c4.xlarge\",\n",
    "    role=role,\n",
    "    sagemaker_session=sagemaker_session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can fit our model, telling it where to look for the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-14 00:36:05 Starting - Starting the training job...\n",
      "2020-03-14 00:36:06 Starting - Launching requested ML instances......\n",
      "2020-03-14 00:37:13 Starting - Preparing the instances for training...\n",
      "2020-03-14 00:37:56 Downloading - Downloading input data...\n",
      "2020-03-14 00:38:10 Training - Downloading the training image...\n",
      "2020-03-14 00:38:51 Failed - Training job failed\n",
      ".."
     ]
    },
    {
     "ename": "UnexpectedStatusException",
     "evalue": "Error for Training job sagemaker-scikit-learn-2020-03-14-00-36-04-771: Failed. Reason: ClientError: Cannot pull algorithm container. Either the image does not exist or its permissions are incorrect.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-61f74a46a0cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_input\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m    463\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 465\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_compilation_job_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m   1061\u001b[0m         \u001b[0;31m# If logs are requested, call logs_for_jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"None\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogs_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1064\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mlogs_for_job\u001b[0;34m(self, job_name, wait, poll, log_type)\u001b[0m\n\u001b[1;32m   3019\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3020\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3021\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_job_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"TrainingJobStatus\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3022\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3023\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36m_check_job_status\u001b[0;34m(self, job, desc, status_key_name)\u001b[0m\n\u001b[1;32m   2613\u001b[0m                 ),\n\u001b[1;32m   2614\u001b[0m                 \u001b[0mallowed_statuses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Completed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Stopped\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2615\u001b[0;31m                 \u001b[0mactual_status\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2616\u001b[0m             )\n\u001b[1;32m   2617\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m: Error for Training job sagemaker-scikit-learn-2020-03-14-00-36-04-771: Failed. Reason: ClientError: Cannot pull algorithm container. Either the image does not exist or its permissions are incorrect."
     ]
    }
   ],
   "source": [
    "sklearn.fit({'train': train_input})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our model is trained, we have two options. First, we can retrieve the actual model (which can also be downloaded to your local machine). Second, we can deploy the model. For our scikit-learn model, will go with the first option. We'll look at the second one for the xgboost model that we'll do next.\n",
    "\n",
    "Let's see where the model output is stored:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'ModelArtifacts'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-5d4bc5bd1f88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m boto3.client('sagemaker').describe_training_job(\n\u001b[0;32m----> 2\u001b[0;31m     TrainingJobName=sklearn.latest_training_job.job_name)['ModelArtifacts']['S3ModelArtifacts']\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'ModelArtifacts'"
     ]
    }
   ],
   "source": [
    "boto3.client('sagemaker').describe_training_job(\n",
    "    TrainingJobName=sklearn.latest_training_job.job_name)['ModelArtifacts']['S3ModelArtifacts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sub in what you see above and then uncomment the following lines\n",
    "#s3.download_file(Bucket = 'sagemaker-us-east-1-339692866702', \n",
    "#                 Key = 'sagemaker-scikit-learn-2020-03-14-00-30-07-534/output/model.tar.gz',\n",
    "#                 Filename = 'model.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "\n",
    "tar = tarfile.open('model.tar.gz')\n",
    "tar.extractall()\n",
    "tar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/base.py:253: UserWarning: Trying to unpickle estimator DecisionTreeRegressor from version 0.20.0 when using version 0.20.3. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/base.py:253: UserWarning: Trying to unpickle estimator RandomForestRegressor from version 0.20.0 when using version 0.20.3. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "rf_model = joblib.load('model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how it does on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf_model.predict(test.iloc[:,1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that the mean absolute error tells us how far off our predictions are, on average, from the true values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116571.19533835458"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(test.iloc[:,0], y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Using sagemaker's XGBoost Algorithm\n",
    "\n",
    "Now, we will see how to use the XGBoost algorithm.\n",
    "\n",
    "We need to get the location of the xgboost model. This is done with the get_image_uri method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = boto3.Session().region_name    \n",
    "smclient = boto3.Session().client('sagemaker')\n",
    "\n",
    "bucket = sagemaker.Session().default_bucket()   \n",
    "prefix = 'housing_xgb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "\n",
    "container = get_image_uri(region, 'xgboost', repo_version='0.90-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, create an Estimator instance, pointing to the xgboost container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = sagemaker.estimator.Estimator(\n",
    "    container,\n",
    "    role, \n",
    "    train_instance_count=1, \n",
    "    train_instance_type='ml.m4.xlarge',\n",
    "    output_path='s3://{}/{}/output'.format(bucket, prefix),\n",
    "    sagemaker_session=sagemaker_session\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the hyperparameters for our model. A list of available hyperparameters and what they represent is available here:https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost_hyperparameters.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.set_hyperparameters(\n",
    "    num_round=100,\n",
    "    rate_drop=0.3,\n",
    "    alpha = 0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Move our training data to s3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'train/train.csv')).upload_file('data/train.csv')\n",
    "s3_input_train = sagemaker.s3_input(s3_data='s3://{}/{}/train'.format(bucket, prefix), content_type='csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-14 00:43:29 Starting - Starting the training job...\n",
      "2020-03-14 00:43:32 Starting - Launching requested ML instances......\n",
      "2020-03-14 00:44:36 Starting - Preparing the instances for training......\n",
      "2020-03-14 00:45:38 Downloading - Downloading input data...\n",
      "2020-03-14 00:46:30 Training - Training image download completed. Training in progress...\u001b[34mINFO:sagemaker-containers:Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34mINFO:sagemaker_xgboost_container.training:Running XGBoost Sagemaker in algorithm mode\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[00:46:33] 17291x85 matrix with 1469735 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34mINFO:root:Single node training.\u001b[0m\n",
      "\u001b[34mINFO:root:Train matrix has 17291 rows\u001b[0m\n",
      "\u001b[34m[0]#011train-rmse:471337\u001b[0m\n",
      "\u001b[34m[1]#011train-rmse:349028\u001b[0m\n",
      "\u001b[34m[2]#011train-rmse:265043\u001b[0m\n",
      "\u001b[34m[3]#011train-rmse:207124\u001b[0m\n",
      "\u001b[34m[4]#011train-rmse:170212\u001b[0m\n",
      "\u001b[34m[5]#011train-rmse:144285\u001b[0m\n",
      "\u001b[34m[6]#011train-rmse:128699\u001b[0m\n",
      "\u001b[34m[7]#011train-rmse:118886\u001b[0m\n",
      "\u001b[34m[8]#011train-rmse:111866\u001b[0m\n",
      "\u001b[34m[9]#011train-rmse:107132\u001b[0m\n",
      "\u001b[34m[10]#011train-rmse:103872\u001b[0m\n",
      "\u001b[34m[11]#011train-rmse:101630\u001b[0m\n",
      "\u001b[34m[12]#011train-rmse:99576.1\u001b[0m\n",
      "\u001b[34m[13]#011train-rmse:97398.9\u001b[0m\n",
      "\u001b[34m[14]#011train-rmse:96156.5\u001b[0m\n",
      "\u001b[34m[15]#011train-rmse:95089.2\u001b[0m\n",
      "\u001b[34m[16]#011train-rmse:93634.5\u001b[0m\n",
      "\u001b[34m[17]#011train-rmse:92691.5\u001b[0m\n",
      "\u001b[34m[18]#011train-rmse:91880.1\u001b[0m\n",
      "\u001b[34m[19]#011train-rmse:90900.6\u001b[0m\n",
      "\u001b[34m[20]#011train-rmse:90002.4\u001b[0m\n",
      "\u001b[34m[21]#011train-rmse:89352.4\u001b[0m\n",
      "\u001b[34m[22]#011train-rmse:88789\u001b[0m\n",
      "\u001b[34m[23]#011train-rmse:88245.1\u001b[0m\n",
      "\u001b[34m[24]#011train-rmse:87594.9\u001b[0m\n",
      "\u001b[34m[25]#011train-rmse:86776.5\u001b[0m\n",
      "\u001b[34m[26]#011train-rmse:86281.7\u001b[0m\n",
      "\u001b[34m[27]#011train-rmse:85815.5\u001b[0m\n",
      "\u001b[34m[28]#011train-rmse:84943.7\u001b[0m\n",
      "\u001b[34m[29]#011train-rmse:84215.5\u001b[0m\n",
      "\u001b[34m[30]#011train-rmse:83930.7\u001b[0m\n",
      "\u001b[34m[31]#011train-rmse:83365.1\u001b[0m\n",
      "\u001b[34m[32]#011train-rmse:83099.1\u001b[0m\n",
      "\u001b[34m[33]#011train-rmse:82732.1\u001b[0m\n",
      "\u001b[34m[34]#011train-rmse:81605.2\u001b[0m\n",
      "\u001b[34m[35]#011train-rmse:81016.5\u001b[0m\n",
      "\u001b[34m[36]#011train-rmse:80434.8\u001b[0m\n",
      "\u001b[34m[37]#011train-rmse:80068.8\u001b[0m\n",
      "\u001b[34m[38]#011train-rmse:79610.3\u001b[0m\n",
      "\u001b[34m[39]#011train-rmse:79375.1\u001b[0m\n",
      "\u001b[34m[40]#011train-rmse:79001.5\u001b[0m\n",
      "\u001b[34m[41]#011train-rmse:78515.6\u001b[0m\n",
      "\u001b[34m[42]#011train-rmse:78143.7\u001b[0m\n",
      "\u001b[34m[43]#011train-rmse:77582.4\u001b[0m\n",
      "\u001b[34m[44]#011train-rmse:77365.6\u001b[0m\n",
      "\u001b[34m[45]#011train-rmse:76725.7\u001b[0m\n",
      "\u001b[34m[46]#011train-rmse:76279.7\u001b[0m\n",
      "\u001b[34m[47]#011train-rmse:76171.2\u001b[0m\n",
      "\u001b[34m[48]#011train-rmse:75831.9\u001b[0m\n",
      "\u001b[34m[49]#011train-rmse:75287.6\u001b[0m\n",
      "\u001b[34m[50]#011train-rmse:75068\u001b[0m\n",
      "\u001b[34m[51]#011train-rmse:74825.6\u001b[0m\n",
      "\u001b[34m[52]#011train-rmse:74645.2\u001b[0m\n",
      "\u001b[34m[53]#011train-rmse:74334.5\u001b[0m\n",
      "\u001b[34m[54]#011train-rmse:74157.7\u001b[0m\n",
      "\u001b[34m[55]#011train-rmse:73886.7\u001b[0m\n",
      "\u001b[34m[56]#011train-rmse:73582.9\u001b[0m\n",
      "\u001b[34m[57]#011train-rmse:73310.8\u001b[0m\n",
      "\u001b[34m[58]#011train-rmse:73136.2\u001b[0m\n",
      "\u001b[34m[59]#011train-rmse:72824.2\u001b[0m\n",
      "\u001b[34m[60]#011train-rmse:72604.4\u001b[0m\n",
      "\u001b[34m[61]#011train-rmse:72454.9\u001b[0m\n",
      "\u001b[34m[62]#011train-rmse:72104.8\u001b[0m\n",
      "\u001b[34m[63]#011train-rmse:71953.9\u001b[0m\n",
      "\u001b[34m[64]#011train-rmse:71653.5\u001b[0m\n",
      "\u001b[34m[65]#011train-rmse:71455.2\u001b[0m\n",
      "\u001b[34m[66]#011train-rmse:71162.5\u001b[0m\n",
      "\u001b[34m[67]#011train-rmse:70892.8\u001b[0m\n",
      "\u001b[34m[68]#011train-rmse:70782.7\u001b[0m\n",
      "\u001b[34m[69]#011train-rmse:70660.3\u001b[0m\n",
      "\u001b[34m[70]#011train-rmse:70421\u001b[0m\n",
      "\u001b[34m[71]#011train-rmse:70252.4\u001b[0m\n",
      "\u001b[34m[72]#011train-rmse:70116.1\u001b[0m\n",
      "\u001b[34m[73]#011train-rmse:69944.8\u001b[0m\n",
      "\u001b[34m[74]#011train-rmse:69672.4\u001b[0m\n",
      "\u001b[34m[75]#011train-rmse:69379.5\u001b[0m\n",
      "\u001b[34m[76]#011train-rmse:68847.9\u001b[0m\n",
      "\u001b[34m[77]#011train-rmse:68483.3\u001b[0m\n",
      "\u001b[34m[78]#011train-rmse:68216.7\u001b[0m\n",
      "\u001b[34m[79]#011train-rmse:67982.3\u001b[0m\n",
      "\u001b[34m[80]#011train-rmse:67780.5\u001b[0m\n",
      "\u001b[34m[81]#011train-rmse:67511.1\u001b[0m\n",
      "\u001b[34m[82]#011train-rmse:67142.4\u001b[0m\n",
      "\u001b[34m[83]#011train-rmse:66849.3\u001b[0m\n",
      "\u001b[34m[84]#011train-rmse:66698.1\u001b[0m\n",
      "\u001b[34m[85]#011train-rmse:66556.6\u001b[0m\n",
      "\u001b[34m[86]#011train-rmse:66242.1\u001b[0m\n",
      "\u001b[34m[87]#011train-rmse:65808.6\u001b[0m\n",
      "\u001b[34m[88]#011train-rmse:65589\u001b[0m\n",
      "\u001b[34m[89]#011train-rmse:65334.7\u001b[0m\n",
      "\u001b[34m[90]#011train-rmse:65109\u001b[0m\n",
      "\u001b[34m[91]#011train-rmse:64791.5\u001b[0m\n",
      "\u001b[34m[92]#011train-rmse:64642.5\u001b[0m\n",
      "\u001b[34m[93]#011train-rmse:64472.6\u001b[0m\n",
      "\u001b[34m[94]#011train-rmse:64206.7\u001b[0m\n",
      "\u001b[34m[95]#011train-rmse:64102.2\u001b[0m\n",
      "\u001b[34m[96]#011train-rmse:63914.4\u001b[0m\n",
      "\u001b[34m[97]#011train-rmse:63698.6\u001b[0m\n",
      "\u001b[34m[98]#011train-rmse:63408.9\u001b[0m\n",
      "\u001b[34m[99]#011train-rmse:63258.7\u001b[0m\n",
      "\n",
      "2020-03-14 00:46:48 Uploading - Uploading generated training model\n",
      "2020-03-14 00:46:48 Completed - Training job completed\n",
      "Training seconds: 70\n",
      "Billable seconds: 70\n"
     ]
    }
   ],
   "source": [
    "xgb.fit({'train': s3_input_train})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's deploy our model. This will create an endpoint holding our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------!"
     ]
    }
   ],
   "source": [
    "predictor = xgb.deploy(initial_instance_count=1, instance_type=\"ml.m4.xlarge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our model deployed, we can use it to make predictions.\n",
    "\n",
    "Notice that it does take a little bit of work to ensure that we are sending our data to the model in the correct format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sagemaker.predictor import csv_serializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.content_type = 'text/csv'\n",
    "predictor.serializer = csv_serializer\n",
    "predictor.deserializer = None\n",
    "\n",
    "def predict(data, rows=500):\n",
    "    split_array = np.array_split(data, int(data.shape[0] / float(rows) + 1))\n",
    "    predictions = ''\n",
    "    for array in split_array:\n",
    "        predictions = ','.join([predictions, predictor.predict(array).decode('utf-8')])\n",
    "\n",
    "    return np.fromstring(predictions[1:], sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = predict(test.values[:, 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71036.91989792968"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(test.iloc[:,0], y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Warning: if you are making a large number of predictions, you will have to do it in batches, because is a cap on how much data you can pass to an endpoint at a time."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
