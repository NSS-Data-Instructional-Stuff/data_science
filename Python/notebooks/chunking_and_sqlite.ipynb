{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chunking and SQLite\n",
    "\n",
    "In this notebook, we'll see a couple of techniques that can be used whe working with large file in Python.\n",
    "\n",
    "Specifically, we'll be looking at the dataset of Metro Nashville Police Department Calls for Service (https://data.nashville.gov/Police/Metro-Nashville-Police-Department-Calls-for-Servic/kwnd-qrrm) with the goal being to look at specific types of calls for service and to bring in additional information, when possible, from the Metro Nashville Police Department Incidents file (https://data.nashville.gov/Police/Metro-Nashville-Police-Department-Incidents/2u6v-ujjs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we do anything else, let's see how many rows are contained in the Calls for Service file. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can start by reading in just a few rows to get an idea of what the dataset we are working with looks like. This can be done using the `nrows` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metro_calls = pd.read_csv('data/Metro_Nashville_Police_Department_Calls_for_Service.csv', \n",
    "                          nrows = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metro_calls.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say that our goal is to find all incidents where the Tencode Description was 'SHOTS FIRED'.\n",
    "\n",
    "One thing we could try is to use the chunksize argument in our pd.read_csv call. What this does is to create an iterable which returns just the specified number of rows at a time.\n",
    "\n",
    "Iterating through a file using chunks can look like this, but can also be structured differently (for example, using a list comprehension).\n",
    "\n",
    "``` \n",
    "chunks = pd.read_csv('data/Metro_Nashville_Police_Department_Calls_for_Service.csv', chunksize = 10000)\n",
    "\n",
    "for chunk in chunks:\n",
    "    # Do something \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is what we need to do:\n",
    "\n",
    "1. Create an iterable by using the chunksize argument.\n",
    "\n",
    "2. For each chunk, filter to just the rows where the 'Tencode Description' column is 'SHOTS FIRED'. Store these rows.\n",
    "\n",
    "3. Concatenate all the results together into a single dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above solution would work for one-off tasks. However, if you are going to be working extensively with a dataset or merging two large datasets, it would be a bit cumbersome to have to chunk through one or both datasets multiple times.\n",
    "\n",
    "As an alternative to working in just Python, we can use a different tool which works better on large datasets - SQL.\n",
    "\n",
    "In this notebook, we will make use of SQLite, which is a file-based relational database management system. We can interact with SQLite databases through the sqlite3 library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to connect to our database. The connect function will either create a new database if one does not already exist or connect to an existing one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = sqlite3.connect('data/police_calls.sqlite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can chunk through the data and for each row, add the rows to a table in our sqlite database. \n",
    "To keep track of how much progress has been made, we can use the `tqdm` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for chunk in tqdm(pd.read_csv('data/Metro_Nashville_Police_Department_Calls_for_Service.csv', chunksize = 10000)):\n",
    "    chunk.columns = [x.lower().replace(' ', '_') for x in chunk.columns]      # Clean up the column names\n",
    "    chunk.to_sql('calls', db, if_exists = 'append', index = False)            # Append the chunk to a calls table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To speed up queries which use a specific column, we can create an **index** on that column. This causes the database to store that column in a way that helps it to retrieve rows quicker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.execute('CREATE INDEX tencode_description ON calls(tencode_description)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we should close our database connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's see how long it takes to find all rows corresponding to 'SHOTS FIRED'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = sqlite3.connect('data/police_calls.sqlite')\n",
    "\n",
    "query = \"SELECT * FROM calls WHERE tencode_description = 'SHOTS FIRED'\"\n",
    "\n",
    "shots_sqlite = pd.read_sql(query, db)\n",
    "\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shots_sqlite.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Metro Police Department Incidents database "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to match calls to incidents, we can use the complaint_number column from the calls database and the incident_number column from the incidents database.\n",
    "\n",
    "To speed up this process, we can created indexes on these two columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = sqlite3.connect('data/police_calls.sqlite')\n",
    "\n",
    "db.execute('CREATE INDEX complaint_number ON calls(complaint_number)')\n",
    "db.execute('CREATE INDEX incident_number ON incidents(incident_number)')\n",
    "\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's grab all SHOTS FIRED calls for which there is an associated incident and bring in the incident information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
