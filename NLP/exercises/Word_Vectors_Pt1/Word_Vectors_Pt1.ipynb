{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aefbf44b",
   "metadata": {},
   "source": [
    "# Word Vectors, Part 1\n",
    "\n",
    "In this notebook, you'll build word vectors using counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9e8485c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "from scipy import sparse\n",
    "from scipy.sparse.linalg import svds\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, regexp_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd0870f",
   "metadata": {},
   "source": [
    "In this notebook, we'll be working with the full text of Moby Dick."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "188d872b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('moby_dick.txt') as fi:\n",
    "    moby = fi.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495fba47",
   "metadata": {},
   "source": [
    "Let's first create a Counter object, `moby_counts` which shows the number of times each token appears in the book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b59d7bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "moby_words = [x.lower() for x in regexp_tokenize(moby, '\\w+')]\n",
    "moby_counter = Counter(moby_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a438a6",
   "metadata": {},
   "source": [
    "Since it will help us out later, we'll build a couple of dictionaries that will let us translate between tokens and indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62388c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = {word: i for i, word in enumerate(moby_counter.keys())}\n",
    "index_word = {i: word for i, word in enumerate(moby_counter.keys())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c06ba2c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index['whale']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e080f0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'whale'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_word[59]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4d97bd",
   "metadata": {},
   "source": [
    "Now, let's split the text into sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fcdc9ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = sent_tokenize(moby)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3b3861",
   "metadata": {},
   "source": [
    "Our next goal is to create a Counter object, `coocurrence_counter` which has keys equal to each pair of tokens and whose values are equal to the number of times this pair of words appears within a window size of 2 of each other.\n",
    "\n",
    "To do this, fill in the following for loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf354e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 2\n",
    "\n",
    "coocurrence_counter = Counter()\n",
    "\n",
    "for sentence in sentences:\n",
    "    sentence = [x.lower() for x in regexp_tokenize(sentence, '\\w+')]\n",
    "    for i, word in enumerate(sentence):\n",
    "        window = # Grab the two words before and the two words after as a list\n",
    "\n",
    "        for other_word in window:\n",
    "            coocurrence_counter[(word, other_word)] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22cfbe3f",
   "metadata": {},
   "source": [
    "Now that we have our coocurrence counts, we need to build our coocurrence matrix.\n",
    "For this task, we'll use a [sparse matrix](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_array.html#scipy-sparse-csr-array) from scipy.\n",
    "\n",
    "This can be created by passing in a tuple (values, (row indices, column indices))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "84dc8b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_idx = []\n",
    "col_idx = []\n",
    "counts = []\n",
    "\n",
    "for (word1, word2) in coocurrence_counter.keys():\n",
    "    row_idx.append(word_index[word1])\n",
    "    col_idx.append(word_index[word2])\n",
    "    counts.append(coocurrence_counter[(word1, word2)])\n",
    "    \n",
    "# We also need to add the diagonal entries\n",
    "for word in moby_counter:\n",
    "    row_idx.append(word_index[word])\n",
    "    col_idx.append(word_index[word])\n",
    "    counts.append(moby_counter[word])\n",
    "\n",
    "cooccurence_matrix = sparse.csc_matrix((counts, (row_idx, col_idx)), dtype = 'float')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676f284a",
   "metadata": {},
   "source": [
    "You can extract out the row at a particular index by using the `.getrow` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1060ed49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x17429 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1002 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cooccurence_matrix.getrow(word_index['whale'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0288c760",
   "metadata": {},
   "source": [
    "You can use the [`cosine_similarity`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.cosine_similarity.html) function to compute similarity between two vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4ef818f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.34003176]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(cooccurence_matrix.getrow(word_index['boat']),\n",
    "                  cooccurence_matrix.getrow(word_index['ship']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3cbe52",
   "metadata": {},
   "source": [
    "**Question:** Which word is most similar to \"ocean\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ee5e7b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1faec9c1",
   "metadata": {},
   "source": [
    "Now, let's take the singular value decomposition to get lower-dimensional vectors. We can use the [`svds`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.svds.html) function from scipy's sparse module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6f757e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension = 50\n",
    "\n",
    "U, D, V = svds(cooccurence_matrix, k = dimension)\n",
    "\n",
    "word_vectors = U * D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb416522",
   "metadata": {},
   "source": [
    "**Question:** Using these new word vectors, which word is most similar to ocean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "67f0ff9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242bb065",
   "metadata": {},
   "source": [
    "Recall that the Positive Pointwise Mutual Information (PPMI) between two words is given by \n",
    "\n",
    "$$PPMI(w_1, w_2) = \\max\\left(\\log_2\\frac{P(w_1, w_2)}{P(w_1)\\cdot P(w_2)}\\right)$$\n",
    "\n",
    "Write a function that takes as input two words and returns the PPMI between those words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cea59e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780f0a03",
   "metadata": {},
   "source": [
    "Now, use this function to build a PPMI matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a5a062db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3d5d69",
   "metadata": {},
   "source": [
    "Apply singular value decomposition to this matrix to get 50-dimensional word vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c1ceff77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0966d63d",
   "metadata": {},
   "source": [
    "How similar are \"sea\" and \"ocean\" using these vectors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "223b0766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
