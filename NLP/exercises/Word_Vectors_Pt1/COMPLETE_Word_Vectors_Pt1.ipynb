{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aefbf44b",
   "metadata": {},
   "source": [
    "# Word Vectors, Part 1\n",
    "\n",
    "In this notebook, you'll build word vectors using counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9e8485c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "from scipy import sparse\n",
    "from scipy.sparse.linalg import svds\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, regexp_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd0870f",
   "metadata": {},
   "source": [
    "In this notebook, we'll be working with the full text of Moby Dick."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "188d872b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/moby_dick.txt') as fi:\n",
    "    moby = fi.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495fba47",
   "metadata": {},
   "source": [
    "Let's first create a Counter object, `moby_counts` which shows the number of times each token appears in the book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b59d7bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "moby_words = [x.lower() for x in regexp_tokenize(moby, '\\w+')]\n",
    "moby_counter = Counter(moby_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a438a6",
   "metadata": {},
   "source": [
    "Since it will help us out later, we'll build a couple of dictionaries that will let us translate between tokens and indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62388c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = {word: i for i, word in enumerate(moby_counter.keys())}\n",
    "index_word = {i: word for i, word in enumerate(moby_counter.keys())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c06ba2c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index['whale']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e080f0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'whale'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_word[59]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4d97bd",
   "metadata": {},
   "source": [
    "Now, let's split the text into sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fcdc9ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = sent_tokenize(moby)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3b3861",
   "metadata": {},
   "source": [
    "Our next goal is to create a Counter object, `coocurrence_counter` which has keys equal to each pair of tokens and whose values are equal to the number of times this pair of words appears within a window size of 2 of each other.\n",
    "\n",
    "To do this, fill in the following for loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf354e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 2\n",
    "\n",
    "coocurrence_counter = Counter()\n",
    "\n",
    "for sentence in sentences:\n",
    "    # First, tokenize the sentence\n",
    "    sentence = # Fill this in\n",
    "    for i, word in enumerate(sentence):\n",
    "        window = # Grab the two words before and the two words after as a list\n",
    "\n",
    "        for other_word in window:\n",
    "            coocurrence_counter[(word, other_word)] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7a4cf66",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 2\n",
    "\n",
    "coocurrence_counter = Counter()\n",
    "\n",
    "for sentence in sentences:\n",
    "    # First, tokenize the sentence\n",
    "    sentence = [x.lower() for x in regexp_tokenize(sentence, '\\w+')]\n",
    "    \n",
    "    # Then, we'll build the window around each word\n",
    "    for i, word in enumerate(sentence):\n",
    "        window = sentence[max(0, i-2): i] + sentence[i+1: i+3]\n",
    "\n",
    "        # Then, we'll up the counter value for that pair\n",
    "        for other_word in window:\n",
    "            coocurrence_counter[(word, other_word)] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22cfbe3f",
   "metadata": {},
   "source": [
    "Now that we have our coocurrence counts, we need to build our coocurrence matrix.\n",
    "For this task, we'll use a [sparse matrix](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_array.html#scipy-sparse-csr-array) from scipy.\n",
    "\n",
    "This can be created by passing in a tuple (values, (row indices, column indices))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "84dc8b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_idx = []\n",
    "col_idx = []\n",
    "counts = []\n",
    "\n",
    "for (word1, word2) in coocurrence_counter.keys():\n",
    "    row_idx.append(word_index[word1])\n",
    "    col_idx.append(word_index[word2])\n",
    "    counts.append(coocurrence_counter[(word1, word2)])\n",
    "    \n",
    "# We also need to add the diagonal entries\n",
    "for word in moby_counter:\n",
    "    row_idx.append(word_index[word])\n",
    "    col_idx.append(word_index[word])\n",
    "    counts.append(moby_counter[word])\n",
    "\n",
    "cooccurence_matrix = sparse.csc_matrix((counts, (row_idx, col_idx)), dtype = 'float')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676f284a",
   "metadata": {},
   "source": [
    "You can extract out the row at a particular index by using the `.getrow` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1060ed49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x17429 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1002 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cooccurence_matrix.getrow(word_index['whale'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0288c760",
   "metadata": {},
   "source": [
    "You can use the [`cosine_similarity`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.cosine_similarity.html) function to compute similarity between two vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4ef818f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.34003176]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(cooccurence_matrix.getrow(word_index['boat']),\n",
    "                  cooccurence_matrix.getrow(word_index['ship']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3cbe52",
   "metadata": {},
   "source": [
    "**Question:** Which word is most similar to \"ocean\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ee5e7b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2d09062a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>ocean</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10407</th>\n",
       "      <td>divides</td>\n",
       "      <td>0.616405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12371</th>\n",
       "      <td>overruns</td>\n",
       "      <td>0.607599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>the</td>\n",
       "      <td>0.600684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2154</th>\n",
       "      <td>inns</td>\n",
       "      <td>0.533608</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           word  similarity\n",
       "525       ocean    1.000000\n",
       "10407   divides    0.616405\n",
       "12371  overruns    0.607599\n",
       "10          the    0.600684\n",
       "2154       inns    0.533608"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = 'ocean'\n",
    "similarities = pd.DataFrame({\n",
    "    'word': word_index.keys(),\n",
    "    'similarity': cosine_similarity(\n",
    "        cooccurence_matrix.getrow(word_index[word]),\n",
    "        cooccurence_matrix)[0]\n",
    "})\n",
    "\n",
    "similarities.sort_values('similarity', ascending = False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1faec9c1",
   "metadata": {},
   "source": [
    "Now, let's take the singular value decomposition to get lower-dimensional vectors. We can use the [`svds`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.svds.html) function from scipy's sparse module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6f757e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension = 50\n",
    "\n",
    "U, D, V = svds(cooccurence_matrix, k = dimension)\n",
    "\n",
    "word_vectors = U * D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb416522",
   "metadata": {},
   "source": [
    "**Question:** Using these new word vectors, which word is most similar to ocean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "67f0ff9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "62ec4a63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>ocean</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>sea</td>\n",
       "      <td>0.974975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>the</td>\n",
       "      <td>0.974912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1120</th>\n",
       "      <td>line</td>\n",
       "      <td>0.972599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>seas</td>\n",
       "      <td>0.971480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word  similarity\n",
       "525   ocean    1.000000\n",
       "330     sea    0.974975\n",
       "10      the    0.974912\n",
       "1120   line    0.972599\n",
       "460    seas    0.971480"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = 'ocean'\n",
    "\n",
    "similarities = pd.DataFrame({\n",
    "    'word': word_index.keys(),\n",
    "    'similarity': cosine_similarity(word_vectors[word_index[word], :].reshape(1, -1), word_vectors)[0]\n",
    "})\n",
    "\n",
    "similarities.sort_values('similarity', ascending = False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242bb065",
   "metadata": {},
   "source": [
    "Recall that the Positive Pointwise Mutual Information (PPMI) between two words is given by \n",
    "\n",
    "$$PPMI(w_1, w_2) = \\max\\left(\\log_2\\frac{P(w_1, w_2)}{P(w_1)\\cdot P(w_2)}\\right)$$\n",
    "\n",
    "Write a function that takes as input two words and returns the PPMI between those words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cea59e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "39833610",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_words = sum(moby_counter.values())\n",
    "total_pairs = sum(coocurrence_counter.values())\n",
    "\n",
    "def ppmi(word1, word2):\n",
    "    numerator = coocurrence_counter[(word1, word2)] / total_pairs\n",
    "    denominator = moby_counter[word1] * moby_counter[word2] / total_words**2\n",
    "    return max(0, np.log2(numerator / denominator))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780f0a03",
   "metadata": {},
   "source": [
    "Now, use this function to build a PPMI matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a5a062db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "29207c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_idx = []\n",
    "col_idx = []\n",
    "ppmis = []\n",
    "\n",
    "for (word1, word2) in coocurrence_counter.keys():\n",
    "    row_idx.append(word_index[word1])\n",
    "    col_idx.append(word_index[word2])\n",
    "    ppmis.append(ppmi(word1, word2))\n",
    "\n",
    "ppmi_matrix = sparse.csc_matrix((ppmis, (row_idx, col_idx)), dtype = 'float')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3d5d69",
   "metadata": {},
   "source": [
    "Apply singular value decomposition to this matrix to get 50-dimensional word vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c1ceff77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8f64d93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension = 50\n",
    "\n",
    "U, D, V = svds(ppmi_matrix, k = dimension)\n",
    "\n",
    "word_vectors_ppmi = U * D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0966d63d",
   "metadata": {},
   "source": [
    "How similar are \"sea\" and \"ocean\" using these vectors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "223b0766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "602004f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_similarity(word1, word2):\n",
    "    return cosine_similarity(word_vectors_ppmi[word_index[word1], :].reshape(1, -1),\n",
    "                  word_vectors_ppmi[word_index[word2], :].reshape(1, -1))[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8ad2d4df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7506885163022181"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_similarity('sea', 'ocean')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
