{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0f7da2-830a-4a67-908d-23f1d9379158",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%conda install -c huggingface -c conda-forge datasets\n",
    "#%conda install -c conda-forge sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "b25a562e-838d-4bed-ae52-ec12552b2406",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from huggingface_hub import hf_hub_download\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import datasets\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD, NMF, LatentDirichletAllocation\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1223d1-aeb6-4022-839d-7ba2eda6aec3",
   "metadata": {},
   "source": [
    "For this exercise, we'll use the first 1000 articles from a dataset of medium articles, which we can download from HuggingFace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ec22a42-51e3-47c2-9311-f6278e1fce75",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = pd.read_csv(\n",
    "  hf_hub_download(\"fabiochiu/medium-articles\", repo_type=\"dataset\", filename=\"medium_articles.csv\")\n",
    ")[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "054312c7-a730-410f-ac76-de13253364b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>url</th>\n",
       "      <th>authors</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mental Note Vol. 24</td>\n",
       "      <td>Photo by Josh Riemer on Unsplash\\n\\nMerry Chri...</td>\n",
       "      <td>https://medium.com/invisible-illness/mental-no...</td>\n",
       "      <td>['Ryan Fan']</td>\n",
       "      <td>2020-12-26 03:38:10.479000+00:00</td>\n",
       "      <td>['Mental Health', 'Health', 'Psychology', 'Sci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Your Brain On Coronavirus</td>\n",
       "      <td>Your Brain On Coronavirus\\n\\nA guide to the cu...</td>\n",
       "      <td>https://medium.com/age-of-awareness/how-the-pa...</td>\n",
       "      <td>['Simon Spichak']</td>\n",
       "      <td>2020-09-23 22:10:17.126000+00:00</td>\n",
       "      <td>['Mental Health', 'Coronavirus', 'Science', 'P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mind Your Nose</td>\n",
       "      <td>Mind Your Nose\\n\\nHow smell training can chang...</td>\n",
       "      <td>https://medium.com/neodotlife/mind-your-nose-f...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2020-10-10 20:17:37.132000+00:00</td>\n",
       "      <td>['Biotechnology', 'Neuroscience', 'Brain', 'We...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The 4 Purposes of Dreams</td>\n",
       "      <td>Passionate about the synergy between science a...</td>\n",
       "      <td>https://medium.com/science-for-real/the-4-purp...</td>\n",
       "      <td>['Eshan Samaranayake']</td>\n",
       "      <td>2020-12-21 16:05:19.524000+00:00</td>\n",
       "      <td>['Health', 'Neuroscience', 'Mental Health', 'P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Surviving a Rod Through the Head</td>\n",
       "      <td>You’ve heard of him, haven’t you? Phineas Gage...</td>\n",
       "      <td>https://medium.com/live-your-life-on-purpose/s...</td>\n",
       "      <td>['Rishav Sinha']</td>\n",
       "      <td>2020-02-26 00:01:01.576000+00:00</td>\n",
       "      <td>['Brain', 'Health', 'Development', 'Psychology...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              title  \\\n",
       "0               Mental Note Vol. 24   \n",
       "1         Your Brain On Coronavirus   \n",
       "2                    Mind Your Nose   \n",
       "3          The 4 Purposes of Dreams   \n",
       "4  Surviving a Rod Through the Head   \n",
       "\n",
       "                                                text  \\\n",
       "0  Photo by Josh Riemer on Unsplash\\n\\nMerry Chri...   \n",
       "1  Your Brain On Coronavirus\\n\\nA guide to the cu...   \n",
       "2  Mind Your Nose\\n\\nHow smell training can chang...   \n",
       "3  Passionate about the synergy between science a...   \n",
       "4  You’ve heard of him, haven’t you? Phineas Gage...   \n",
       "\n",
       "                                                 url                 authors  \\\n",
       "0  https://medium.com/invisible-illness/mental-no...            ['Ryan Fan']   \n",
       "1  https://medium.com/age-of-awareness/how-the-pa...       ['Simon Spichak']   \n",
       "2  https://medium.com/neodotlife/mind-your-nose-f...                      []   \n",
       "3  https://medium.com/science-for-real/the-4-purp...  ['Eshan Samaranayake']   \n",
       "4  https://medium.com/live-your-life-on-purpose/s...        ['Rishav Sinha']   \n",
       "\n",
       "                          timestamp  \\\n",
       "0  2020-12-26 03:38:10.479000+00:00   \n",
       "1  2020-09-23 22:10:17.126000+00:00   \n",
       "2  2020-10-10 20:17:37.132000+00:00   \n",
       "3  2020-12-21 16:05:19.524000+00:00   \n",
       "4  2020-02-26 00:01:01.576000+00:00   \n",
       "\n",
       "                                                tags  \n",
       "0  ['Mental Health', 'Health', 'Psychology', 'Sci...  \n",
       "1  ['Mental Health', 'Coronavirus', 'Science', 'P...  \n",
       "2  ['Biotechnology', 'Neuroscience', 'Brain', 'We...  \n",
       "3  ['Health', 'Neuroscience', 'Mental Health', 'P...  \n",
       "4  ['Brain', 'Health', 'Development', 'Psychology...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1dd653-5f83-4dc8-af43-9f0e0ea58946",
   "metadata": {},
   "source": [
    "We can inspect a few of the articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65e6836f-5f36-4b60-b21b-b9cbf7e5ac06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Mental Note Vol. 24\n",
      "\n",
      "Text: Photo by Josh Riemer on Unsplash\n",
      "\n",
      "Merry Christmas and Happy Holidays, everyone!\n",
      "\n",
      "We just wanted everyone to know how much we appreciate everyone and how thankful we are for all our readers and writers here. We wouldn’t be anywhere without you, so thank you all for bringing informative, vulnerable, and important pieces that destigmatize mental illness and mental health.\n",
      "\n",
      "Without further ado, here are ten of our top stories from last week, all of which were curated:\n",
      "\n",
      "“Just as the capacity to love and inspire is universal so is the capacity to hate and discourage. Irrespective of gender, race, age or religion none of us are exempt from aggressive proclivities. Those who are narcissistically disordered, and accordingly repress deep seated feelings of inferiority with inflated delusions of grandeur and superiority, are more prone to aggression and violence. They infiltrate our interactions in myriad environments from home, work, school and the cyber world. Hence, bullying does not happen in isolation. Although there is a ringleader she looks to her minions to either sanction her cruelty or look the other way.”\n",
      "\n",
      "“Even though the circumstances that brought me here were sad and challenging, I’m grateful for how this program has changed my life for the better. I can’t help but imagine what life would be like if everyone learned to accept their powerlessness over other people, prioritize their serenity, and take life one step at a time. We’ll never know, but I’d bet the world would be much happier.”\n",
      "\n",
      "“The prospect of spending a horrible Christmas, locked in on a psychiatric unit, was one of the low points of my life. For weeks, the day room was festooned with cheesy decorations and a sorry pink aluminum tree. All of our “activity” therapies revolved around the holidays. We baked and decorated cookies. We fashioned quick-drying clay into ornaments that turned out to be too heavy for the tree. Crappy Christmas carols were background torture. It was hard to get pissed off at the staff because they were making the best with what they had.”\n",
      "\n",
      "“Although I hate to admit it, even if my ex had never betrayed me, I still wouldn’t have been happy. I had set him up for an impossible job — to define me and make me whole. If I cannot find peace and contentment within myself, how could anyone else do it for me?”\n",
      "\n",
      "“On a personal note, significant feelings of loss and sadness can still flare up from time to time. That’s only natural; it’s no reason for self-critique. No matter how resilient we purport to be, we are all emotionally vulnerable human beings. Besides, we aren’t talking about some conceptual loss that we can just mechanically compartmentalize away — we are talking about the loss of our fathers, mothers, sisters and brothers.”\n",
      "\n",
      "“The next six weeks will be hard as cases continue to explode and government leadership remains nonexistent. I can’t control any of this. The only thing I can do is take deep breaths, remain vigilant when it comes to limiting exposure to the virus, and let lots of stuff go. I may always be a hypochondriac, but now that I recognize the beast, I’m hopeful I’ll be able to tame it.”\n",
      "\n",
      "“From anecdotal news reports and informal surveys, there is evidence that for some of us, this pandemic-imposed isolation is a boon rather than a trial. One study on mixed emotions showed that those with lower emotional stability (“moody” personalities) are actually better at responding to uncertainty.”\n",
      "\n",
      "“Every day I wish in my heart and soul that I didn’t have ME/CFS. Unfortunately, I do. It’s a result of a virus I had; 10–12 percent of people who experience a serious infection go on to develop ME. I’ve visualized life without CFS for over a year now; I can smell life without it, I can taste it. It’s in the smell of the lavender fields that I can no longer run through. It’s in the taste of the meals from my favorite restaurant that I can no longer walk to. It’s on the tip of my tongue. It’s in the potentialities; all the things I could be doing, as a twenty-four year-old, that I can’t. I cannot cross the chasm between the potential and the reality. And that’s nothing to do with manifestation.”\n",
      "\n",
      "“Whether it’s cabin fever, redundancy, loss, or general Covid anxieties, this year has caused us to be exposed to more uncertainty than ever. Uncertainty creates unease and feelings of stress. Some of us may have taken this year as one to motivate — plan dream trips, and prepare and be inspired for what the future could bring. For the rest, it has caused us to become irrational, emotional, and reserved.\n",
      "\n",
      "“To be more self-compassionate is a task that can be tricky because we always want to push ourselves and do better. Without realising it, this can lead to us being self-critical which can have damaging consequences.\n",
      "\n",
      "It’s important to notice these times when we are harsh because we can easily turn it into self-compassion, which is linked to a better quality of life.”\n",
      "\n",
      "Merry Christmas and Happy Holidays, everyone!\n",
      "\n",
      "— Ryan, Juliette, Marie, and Meredith\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "print(f'Title: {articles.loc[i,\"title\"]}\\n')\n",
    "\n",
    "print(f'Text: {articles.loc[i,\"text\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32294485-637d-4b77-9a9d-2badcdfeb6dd",
   "metadata": {},
   "source": [
    "### Method 1: Bag of Words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b788ee0-3070-4704-be92-8c442ff4c6d9",
   "metadata": {},
   "source": [
    "Fit a CountVectorizer to the text of the articles with all of the defaults.  Then vectorize the dataset using the fit vectorizer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4cc272-474c-4b48-9e77-5a80cb13534d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2ee08b-50fa-468c-9655-47b110fa855b",
   "metadata": {},
   "source": [
    "**Question:** How many dimensions do the embeddings have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "03208e89-aa86-4daa-bbd8-5952cfe2df2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eecfe606-937c-409e-823a-745fe380d407",
   "metadata": {},
   "source": [
    "Now, let's use the embeddings to look for similar articles to a search query.\n",
    "\n",
    "Apply the vectorizer you fit earlier to this query string to get an embedding. \n",
    "\n",
    "**Hint:** A vectorizer will expect you to pass in a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3f38271b-eb14-4619-8f00-604bcf9bbdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"how to build a neural network model\"\n",
    "\n",
    "# Your code to transform the search query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f2c931-5dcd-49b7-aa8f-b5bdab82a541",
   "metadata": {},
   "source": [
    "Now, we need to find the similarity between our query embedding and each vectorized article.\n",
    "\n",
    "For this, you can use the [cosine similarity function from scikit-learn.](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.cosine_similarity.html)\n",
    "\n",
    "Calculate the similarity between the query embedding and each article embedding and save the result to a variable named `similarity_scores`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2b4369-830a-4ad4-8a3b-1528bbb77a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef6eddc-b0a1-4fd0-8381-797313e2bcaa",
   "metadata": {},
   "source": [
    "Now, we need to find the most similar results. To help with this, we can use the [argsort function from numpy](https://numpy.org/doc/stable/reference/generated/numpy.argsort.html), which will give the indices sorted by value. \n",
    "\n",
    "Use the argsort function to find the indices of the 5 most similar articles. Then, find the titles of the most similar articles. **Warning:** argsort sorts from smallest to largest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9b3dffd0-5992-4879-a207-08dcc74afca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9310f85a-89eb-4bc6-a0d7-9bd799abaa0b",
   "metadata": {},
   "source": [
    "To make it easier to try out different methods, write a function that takes a vectorized query string and an array of embeddings and returns the index of the n most similar articles. You can make it default to returning the 5 most similar articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3311d604-08c9-4b75-b403-efd85be82b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbe41e8-ce2b-4eb2-a1fd-e79cd4230c84",
   "metadata": {},
   "source": [
    "Try out your function. See how it does on the query \"how to build a neural network model\", or try other queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774b08ac-a7bb-43bc-a53e-1f0a68f7f5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db669b82-b3c3-4836-8139-2b2b8aa5b0d5",
   "metadata": {},
   "source": [
    "Fit a new CountVectorizer, but this time, remove stop words. \n",
    "\n",
    "**Hint:** this can be done using the `stop_words` argument to the [count vectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86c503a-589d-4834-be23-435f9aec05ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e1c91e-f935-48cc-8244-021e260b9756",
   "metadata": {},
   "source": [
    "**Question:** How many dimensions are your embeddings once stop words have been removed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3fcbd2da-1282-4e9b-95be-cdf3aec8b671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f78ac7-41d1-4187-a624-3c37d5a61957",
   "metadata": {},
   "source": [
    "Now, apply your function from above but using the new vectorizer. How do the results compare?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161210c0-3629-4175-87fb-1e2d38779404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb94c418-8156-4e76-b41b-26276400a92a",
   "metadata": {},
   "source": [
    "Try using a tfidf vectorizer. How do the results compare?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d86e96-1b0a-4cc5-9538-6da602323e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed45785-5b64-4234-935a-2bb6e3636d5c",
   "metadata": {},
   "source": [
    "### Method 2: Using a Pretrained Embedding Model\n",
    "\n",
    "Now, let's compare how we do using the [all-MiniLM-L6-v2 embedding model](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2).\n",
    "\n",
    "This will create a 384-dimensional dense embedding of each sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c08b104a-2599-4f02-8bd0-147205f3ffe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "369b82b2-a0a3-44be-b89b-097d72a53521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6.76569268e-02  6.34959415e-02  4.87130806e-02  7.93049559e-02\n",
      "   3.74480784e-02  2.65278225e-03  3.93749215e-02 -7.09844055e-03\n",
      "   5.93614355e-02  3.15369926e-02  6.00980595e-02 -5.29052168e-02\n",
      "   4.06068005e-02 -2.59308647e-02  2.98428331e-02  1.12690707e-03\n",
      "   7.35148937e-02 -5.03818206e-02 -1.22386597e-01  2.37028245e-02\n",
      "   2.97265425e-02  4.24768627e-02  2.56337468e-02  1.99516676e-03\n",
      "  -5.69190606e-02 -2.71598399e-02 -3.29035260e-02  6.60248920e-02\n",
      "   1.19007193e-01 -4.58791107e-02 -7.26214573e-02 -3.25840451e-02\n",
      "   5.23413606e-02  4.50553074e-02  8.25298484e-03  3.67024131e-02\n",
      "  -1.39415544e-02  6.53918609e-02 -2.64272243e-02  2.06351076e-04\n",
      "  -1.36643751e-02 -3.62810940e-02 -1.95043683e-02 -2.89737582e-02\n",
      "   3.94270718e-02 -8.84090737e-02  2.62424909e-03  1.36713888e-02\n",
      "   4.83062826e-02 -3.11566070e-02 -1.17329173e-01 -5.11690639e-02\n",
      "  -8.85287598e-02 -2.18962915e-02  1.42986206e-02  4.44167517e-02\n",
      "  -1.34816011e-02  7.43392557e-02  2.66382471e-02 -1.98762342e-02\n",
      "   1.79191455e-02 -1.06052002e-02 -9.04262662e-02  2.13269144e-02\n",
      "   1.41204819e-01 -6.47176849e-03 -1.40382349e-03 -1.53609915e-02\n",
      "  -8.73571858e-02  7.22173899e-02  2.01403350e-02  4.25587408e-02\n",
      "  -3.49014252e-02  3.19500803e-04 -8.02971423e-02 -3.27472351e-02\n",
      "   2.85268612e-02 -5.13658039e-02  1.09389178e-01  8.19327533e-02\n",
      "  -9.84039754e-02 -9.34096426e-02 -1.51292067e-02  4.51249070e-02\n",
      "   4.94172163e-02 -2.51867995e-02  1.57077387e-02 -1.29290715e-01\n",
      "   5.31892758e-03  4.02341876e-03 -2.34572180e-02 -6.72982484e-02\n",
      "   2.92280279e-02 -2.60845702e-02  1.30624874e-02 -3.11663244e-02\n",
      "  -4.82713543e-02 -5.58859296e-02 -3.87504958e-02  1.20010890e-01\n",
      "  -1.03924507e-02  4.89705466e-02  5.53537421e-02  4.49357852e-02\n",
      "  -4.00979072e-03 -1.02959789e-01 -2.92968638e-02 -5.83402440e-02\n",
      "   2.70472225e-02 -2.20168885e-02 -7.22240880e-02 -4.13869955e-02\n",
      "  -1.93298087e-02  2.73327506e-03  2.77021172e-04 -9.67588723e-02\n",
      "  -1.00574732e-01 -1.41922645e-02 -8.07892233e-02  4.53925431e-02\n",
      "   2.45041270e-02  5.97613715e-02 -7.38184974e-02  1.19844070e-02\n",
      "  -6.63403645e-02 -7.69045204e-02  3.85158136e-02 -5.59362293e-33\n",
      "   2.80013774e-02 -5.60785048e-02 -4.86601591e-02  2.15569306e-02\n",
      "   6.01981170e-02 -4.81402725e-02 -3.50247435e-02  1.93314124e-02\n",
      "  -1.75152123e-02 -3.89210433e-02 -3.81059130e-03 -1.70288235e-02\n",
      "   2.82099899e-02  1.28290839e-02  4.71601039e-02  6.21029846e-02\n",
      "  -6.43590018e-02  1.29285619e-01 -1.31231397e-02  5.23069687e-02\n",
      "  -3.73680852e-02  2.89094616e-02 -1.68981310e-02 -2.37330515e-02\n",
      "  -3.33491825e-02 -5.16762510e-02  1.55356461e-02  2.08802745e-02\n",
      "  -1.25371963e-02  4.59578745e-02  3.72719988e-02  2.80566830e-02\n",
      "  -5.90005107e-02 -1.16988048e-02  4.92182411e-02  4.70328853e-02\n",
      "   7.35487640e-02 -3.70529965e-02  3.98458401e-03  1.06411958e-02\n",
      "  -1.61509146e-04 -5.27166426e-02  2.75927670e-02 -3.92920896e-02\n",
      "   8.44717324e-02  4.86861132e-02 -4.85873362e-03  1.79948527e-02\n",
      "  -4.28569689e-02  1.23375403e-02  6.39958866e-03  4.04823422e-02\n",
      "   1.48886908e-02 -1.53941000e-02  7.62948245e-02  2.37044115e-02\n",
      "   4.45236973e-02  5.08195944e-02 -2.31251423e-03 -1.88736580e-02\n",
      "  -1.23335272e-02  4.66001853e-02 -5.63437454e-02  6.29927516e-02\n",
      "  -3.15535143e-02  3.24912183e-02  2.34673340e-02 -6.55438602e-02\n",
      "   2.01709494e-02  2.57082582e-02 -1.23869115e-02 -8.36493075e-03\n",
      "  -6.64377734e-02  9.43073258e-02 -3.57093103e-02 -3.42483111e-02\n",
      "  -6.66356971e-03 -8.01525544e-03 -3.09711099e-02  4.33012508e-02\n",
      "  -8.21398851e-03 -1.50795072e-01  3.07692084e-02  4.00719196e-02\n",
      "  -3.79293263e-02  1.93213462e-03  4.00530435e-02 -8.77075121e-02\n",
      "  -3.68490517e-02  8.57956894e-03 -3.19251679e-02 -1.25257624e-02\n",
      "   7.35540241e-02  1.34737801e-03  2.05918346e-02  2.71098330e-33\n",
      "  -5.18576801e-02  5.78361042e-02 -9.18985009e-02  3.94421592e-02\n",
      "   1.05576538e-01 -1.96912307e-02  6.18401729e-02 -7.63464868e-02\n",
      "   2.40880623e-02  9.40048993e-02 -1.16535448e-01  3.71198729e-02\n",
      "   5.22425324e-02 -3.95857869e-03  5.72214276e-02  5.32849785e-03\n",
      "   1.24016911e-01  1.39022488e-02 -1.10250199e-02  3.56053449e-02\n",
      "  -3.30754742e-02  8.16574544e-02 -1.52003895e-02  6.05585128e-02\n",
      "  -6.01397827e-02  3.26102488e-02 -3.48296836e-02 -1.69881899e-02\n",
      "  -9.74907130e-02 -2.71484181e-02  1.74712541e-03 -7.68981874e-02\n",
      "  -4.31858301e-02 -1.89985074e-02 -2.91661043e-02  5.77488467e-02\n",
      "   2.41821259e-02 -1.16902180e-02 -6.21435195e-02  2.84351427e-02\n",
      "  -2.37509026e-04 -2.51783244e-02  4.39638877e-03  8.12839791e-02\n",
      "   3.64183784e-02 -6.04006499e-02 -3.65517624e-02 -7.93748647e-02\n",
      "  -5.08521823e-03  6.69698715e-02 -1.17784381e-01  3.23743410e-02\n",
      "  -4.71252687e-02 -1.34459510e-02 -9.48444456e-02  8.24952126e-03\n",
      "  -1.06748994e-02 -6.81881532e-02  1.11816172e-03  2.48020161e-02\n",
      "  -6.35889471e-02  2.84492448e-02 -2.61303559e-02  8.58111382e-02\n",
      "   1.14682227e-01 -5.35345674e-02 -5.63588776e-02  4.26009223e-02\n",
      "   1.09454496e-02  2.09579747e-02  1.00131117e-01  3.26050967e-02\n",
      "  -1.84208766e-01 -3.93208712e-02 -6.91454932e-02 -6.38104528e-02\n",
      "  -6.56385198e-02 -6.41251588e-03 -4.79612574e-02 -7.68132731e-02\n",
      "   2.95384545e-02 -2.29948517e-02  4.17036936e-02 -2.50047594e-02\n",
      "  -4.54510609e-03 -4.17136438e-02 -1.32289575e-02 -6.38357177e-02\n",
      "  -2.46470748e-03 -1.37337744e-02  1.68976542e-02 -6.30398020e-02\n",
      "   8.98880661e-02  4.18171287e-02 -1.85687393e-02 -1.80442168e-08\n",
      "  -1.67998020e-02 -3.21577564e-02  6.30383864e-02 -4.13091816e-02\n",
      "   4.44819294e-02  2.02465779e-03  6.29592091e-02 -5.17371064e-03\n",
      "  -1.00444276e-02 -3.05640046e-02  3.52672599e-02  5.58581986e-02\n",
      "  -4.67125401e-02  3.45103033e-02  3.29578146e-02  4.30114679e-02\n",
      "   2.94360612e-02 -3.03164665e-02 -1.71107743e-02  7.37484843e-02\n",
      "  -5.47910705e-02  2.77515445e-02  6.20162720e-03  1.58800762e-02\n",
      "   3.42978910e-02 -5.15750330e-03  2.35080142e-02  7.53135756e-02\n",
      "   1.92843322e-02  3.36197130e-02  5.09103797e-02  1.52497038e-01\n",
      "   1.64207369e-02  2.70528775e-02  3.75161991e-02  2.18553226e-02\n",
      "   5.66333905e-02 -3.95746455e-02  7.12313503e-02 -5.41377477e-02\n",
      "   1.03765458e-03  2.11853143e-02 -3.56309302e-02  1.09016910e-01\n",
      "   2.76533584e-03  3.13997641e-02  1.38417538e-03 -3.45738865e-02\n",
      "  -4.59277518e-02  2.88083199e-02  7.16902548e-03  4.84684780e-02\n",
      "   2.61017978e-02 -9.44072939e-03  2.82169897e-02  3.48724835e-02\n",
      "   3.69098447e-02 -8.58949870e-03 -3.53205353e-02 -2.47856639e-02\n",
      "  -1.91920940e-02  3.80707681e-02  5.99653199e-02 -4.22287174e-02]\n",
      " [ 8.64386037e-02  1.02762640e-01  5.39455144e-03  2.04441720e-03\n",
      "  -9.96336807e-03  2.53855158e-02  4.92875129e-02 -3.06265503e-02\n",
      "   6.87254667e-02  1.01365671e-02  7.75397420e-02 -9.00807455e-02\n",
      "   6.10619457e-03 -5.69898859e-02  1.41714429e-02  2.80492008e-02\n",
      "  -8.68464783e-02  7.64399022e-02 -1.03491321e-01 -6.77438155e-02\n",
      "   6.99946731e-02  8.44250768e-02 -7.24911876e-03  1.04770446e-02\n",
      "   1.34021053e-02  6.77576736e-02 -9.42086428e-02 -3.71689871e-02\n",
      "   5.22617325e-02 -3.10853235e-02 -9.63406935e-02  1.57717019e-02\n",
      "   2.57866737e-02  7.85244927e-02  7.89949149e-02  1.91516075e-02\n",
      "   1.64356250e-02  3.10090161e-03  3.81311476e-02  2.37091016e-02\n",
      "   1.05389804e-02 -4.40644734e-02  4.41738702e-02 -2.58728229e-02\n",
      "   6.15378693e-02 -4.05427739e-02 -8.64140019e-02  3.19722481e-02\n",
      "  -8.90644907e-04 -2.44437177e-02 -9.19720978e-02  2.33939420e-02\n",
      "  -8.30293447e-02  4.41510305e-02 -2.49692909e-02  6.23019896e-02\n",
      "  -1.30352192e-03  7.51395673e-02  2.46384554e-02 -6.47244453e-02\n",
      "  -1.17727742e-01  3.83391902e-02 -9.11767259e-02  6.35445863e-02\n",
      "   7.62739554e-02 -8.80241096e-02  9.54558793e-03 -4.69717681e-02\n",
      "  -8.41740668e-02  3.88823301e-02 -1.14393547e-01  6.28857547e-03\n",
      "  -3.49361226e-02  2.39750426e-02 -3.31317000e-02 -1.57244038e-02\n",
      "  -3.78955267e-02 -8.81251972e-03  7.06118643e-02  3.28066386e-02\n",
      "   2.03671330e-03 -1.12278983e-01  6.79720007e-03  1.22765526e-02\n",
      "   3.35303620e-02 -1.36200553e-02 -2.25489903e-02 -2.25228686e-02\n",
      "  -2.03195028e-02  5.04297391e-02 -7.48652890e-02 -8.22822154e-02\n",
      "   7.65962899e-02  4.93392050e-02 -3.75553295e-02  1.44634685e-02\n",
      "  -5.72457537e-02 -1.79954395e-02  1.09697938e-01  1.19462758e-01\n",
      "   8.09216581e-04  6.17057346e-02  3.26322839e-02 -1.30780071e-01\n",
      "  -1.48636639e-01 -6.16232492e-02  4.33886126e-02  2.67129336e-02\n",
      "   1.39785968e-02 -3.94002460e-02 -2.52711885e-02  3.87741090e-03\n",
      "   3.58664580e-02 -6.15420192e-02  3.76660377e-02  2.67565195e-02\n",
      "  -3.82659175e-02 -3.54793258e-02 -2.39227302e-02  8.67977217e-02\n",
      "  -1.84062999e-02  7.71039426e-02  1.39866606e-03  7.00383261e-02\n",
      "  -4.77877483e-02 -7.89819807e-02  5.10814711e-02 -2.99868223e-33\n",
      "  -3.91646437e-02 -2.56211730e-03  1.65210664e-02  9.48935840e-03\n",
      "  -5.66219389e-02  6.57782704e-02 -4.77002896e-02  1.11661870e-02\n",
      "  -5.73558398e-02 -9.16258805e-03 -2.17521060e-02 -5.59531450e-02\n",
      "  -1.11422725e-02  9.32793245e-02  1.66765358e-02 -1.36723472e-02\n",
      "   4.34388667e-02  1.87239063e-03  7.29949307e-03  5.16331904e-02\n",
      "   4.80608605e-02  1.35341436e-01 -1.71738937e-02 -1.29698701e-02\n",
      "  -7.50109926e-02  2.61107534e-02  2.69802138e-02  7.83094147e-04\n",
      "  -4.87270020e-02  1.17842685e-02 -4.59580682e-02 -4.83213700e-02\n",
      "  -1.95670836e-02  1.93889234e-02  1.98807362e-02  1.67432446e-02\n",
      "   9.87800881e-02 -2.74087638e-02  2.34809201e-02  3.70228081e-03\n",
      "  -6.14514835e-02 -1.21229282e-03 -9.50472336e-03  9.25153401e-03\n",
      "   2.38444060e-02  8.61231983e-02  2.26789713e-02  5.45146700e-04\n",
      "   3.47129256e-02  6.25465857e-03 -6.92776777e-03  3.92400399e-02\n",
      "   1.15674799e-02  3.26279998e-02  6.22155666e-02  2.76114438e-02\n",
      "   1.86883807e-02  3.55805829e-02  4.11795788e-02  1.54781835e-02\n",
      "   4.22691256e-02  3.82248126e-02  1.00313649e-02 -2.83246059e-02\n",
      "   4.47052605e-02 -4.10458557e-02 -4.50545037e-03 -5.44734113e-02\n",
      "   2.62321010e-02  1.79862492e-02 -1.23118743e-01 -4.66952063e-02\n",
      "  -1.35913165e-02  6.46710098e-02  3.57350451e-03 -1.22234197e-02\n",
      "  -1.79381985e-02 -2.55502239e-02  2.37224158e-02  4.08667186e-03\n",
      "  -6.51476085e-02  4.43651602e-02  4.68595996e-02 -3.25174890e-02\n",
      "   4.02268535e-03 -3.97600885e-03  1.11939674e-02 -9.95597616e-02\n",
      "   3.33168656e-02  8.01060796e-02  9.42692086e-02 -6.38293847e-02\n",
      "   3.23151350e-02 -5.13553433e-02 -7.49880541e-03  5.30048678e-34\n",
      "  -4.13195081e-02  9.49646756e-02 -1.06401406e-01  4.96590510e-02\n",
      "  -3.41913328e-02 -3.16745751e-02 -1.71556156e-02  1.70103915e-03\n",
      "   5.79757765e-02 -1.21776573e-03 -1.68535914e-02 -5.16912490e-02\n",
      "   5.52998781e-02 -3.42647843e-02  3.08179390e-02 -3.10481209e-02\n",
      "   9.27532613e-02  3.72663699e-02 -2.37398073e-02  4.45893779e-02\n",
      "   1.46153374e-02  1.16239384e-01 -5.00112772e-02  3.88716385e-02\n",
      "   4.24743723e-03  2.56976709e-02  3.27243842e-02  4.29907516e-02\n",
      "  -1.36144320e-02  2.56122239e-02  1.06262825e-02 -8.46863762e-02\n",
      "  -9.52982157e-02  1.08399861e-01 -7.51600042e-02 -1.37773436e-02\n",
      "   6.37338459e-02 -4.49669873e-03 -3.25321555e-02  6.23614155e-02\n",
      "   3.48052904e-02 -3.54922600e-02 -2.00222712e-02  3.66608091e-02\n",
      "  -2.48837378e-02  1.01818526e-02 -7.01232776e-02 -4.31950763e-02\n",
      "   2.95332596e-02 -2.94882833e-04 -3.45386900e-02  1.46676088e-02\n",
      "  -9.83970314e-02 -4.70487997e-02 -8.85496568e-03 -8.89913961e-02\n",
      "   3.50995660e-02 -1.29601955e-01 -4.98865917e-02 -6.12047389e-02\n",
      "  -5.97797483e-02  9.46321245e-03  4.91217859e-02 -7.75026381e-02\n",
      "   8.09727088e-02 -4.79257144e-02  2.34377314e-03  7.57031590e-02\n",
      "  -2.40175724e-02 -1.52545944e-02  4.86738645e-02 -3.85968238e-02\n",
      "  -7.04831630e-02 -1.20348483e-02 -3.88791002e-02 -7.76016861e-02\n",
      "  -1.07243937e-02  1.04188416e-02 -2.13753525e-02 -9.17386413e-02\n",
      "  -1.11344801e-02 -2.96066273e-02  2.46458445e-02  4.65713814e-03\n",
      "  -1.63449682e-02 -3.95219699e-02  7.73373619e-02 -2.84732934e-02\n",
      "  -3.69936903e-03  8.27665031e-02 -1.10408720e-02  3.13983224e-02\n",
      "   5.35094291e-02  5.75145930e-02 -3.17622088e-02 -1.52911230e-08\n",
      "  -7.99661279e-02 -4.76796925e-02 -8.59789103e-02  5.69616370e-02\n",
      "  -4.08866815e-02  2.23832522e-02 -4.64449776e-03 -3.80130932e-02\n",
      "  -3.10670901e-02 -1.07277771e-02  1.97698623e-02  7.76998093e-03\n",
      "  -6.09474909e-03 -3.86376008e-02  2.80272011e-02  6.78137764e-02\n",
      "  -2.35351454e-02  3.21747363e-02  8.02538637e-03 -2.39107180e-02\n",
      "  -1.21994852e-03  3.14598940e-02 -5.24923876e-02 -8.06820020e-03\n",
      "   3.14771780e-03  5.11496812e-02 -4.44104411e-02  6.36013597e-02\n",
      "   3.85083817e-02  3.30432840e-02 -4.18726075e-03  4.95592728e-02\n",
      "  -5.69604971e-02 -6.49715727e-03 -2.49792580e-02 -1.60866827e-02\n",
      "   6.62289411e-02 -2.06310768e-02  1.08045742e-01  1.68546867e-02\n",
      "   1.43812522e-02 -1.32127739e-02 -1.29387423e-01  6.95216507e-02\n",
      "  -5.55773079e-02 -6.75413385e-02 -5.45819942e-03 -6.13594148e-03\n",
      "   3.90840843e-02 -6.28779307e-02  3.74063216e-02 -1.16570974e-02\n",
      "   1.29150050e-02 -5.52495420e-02  5.16076013e-02 -4.30841465e-03\n",
      "   5.80248050e-02  1.86944809e-02  2.27810610e-02  3.21665443e-02\n",
      "   5.37978858e-02  7.02848807e-02  7.49312267e-02 -8.41774940e-02]]\n"
     ]
    }
   ],
   "source": [
    "sentences = [\"This is an example sentence\", \"Each sentence is converted\"]\n",
    "\n",
    "embeddings = embedder.encode(sentences)\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf339d4b-23e6-4034-84bf-7198135f758a",
   "metadata": {},
   "source": [
    "Use this new embedder to vectorize the articles and then find the most similar to the query. How do the results compare to the other methods?\n",
    "\n",
    "**Warning:** Creating embeddings for all of the articles may take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d101fa3e-8650-48d5-aff4-9ee49b28a73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323f5908-c41b-4f96-a3a0-d4d7843d67cf",
   "metadata": {},
   "source": [
    "### Method 3: Topic Models Embeddings\n",
    "\n",
    "Another method to get a vector representation of a document is through a **topic model**. A topic model usually seeks to uncover some number of latent topics in a collection of documents and to assign a distribution of topics per document.  \n",
    "\n",
    "Scikit-learn has multiple implementations of topic models, including [latent semantic analysis](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html), [nonnegative matrix factorization](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.NMF.html) and [latent Dirichlet allocation](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html).\n",
    "\n",
    "For these models, you'll want to input the bag-of-words associated with each article."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad0fb8f-0d95-4ce4-9296-f62e69eabd8b",
   "metadata": {},
   "source": [
    "Start by making a pipeline which contains a vectorizer followed by a [TruncatedSVD](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html) object with 25 components.\n",
    "\n",
    "Fit this pipeline to the articles and then find the most similar article to the search query, as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ea3284-e55e-4a8a-b483-dbaf3e2ff4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25efc5f3-1e94-4361-9336-f67950720217",
   "metadata": {},
   "source": [
    "Now, see what words are making up the first few topics. \n",
    "\n",
    "**Hint:** You can get the vocabulary out of the vectorizer using the `get_feature_names_out` method, and you can access the components of each topic using the `components_` attribute of the topic model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e34cab-34ef-4855-b174-c88c21a91599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2fc260-ffa9-45df-ad98-86e8c13fdcd5",
   "metadata": {},
   "source": [
    "Try adjusting some of the parameters, such as changing the type of vectorizer or excluding stop words. How does that change your results?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b3386b-3d0a-4206-8dc5-7f54efee6b72",
   "metadata": {},
   "source": [
    "Finally, try out [nonnegative matrix factorization](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.NMF.html) and [latent Dirichlet allocation](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html).\n",
    "\n",
    "How do those models compare?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
