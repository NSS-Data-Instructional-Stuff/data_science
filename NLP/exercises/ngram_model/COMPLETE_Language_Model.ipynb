{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84f5b0dc",
   "metadata": {},
   "source": [
    "## N-gram Model From Scratch\n",
    "\n",
    "In this notebook, we'll implement a simple ngram language model using the text from Moby Dick."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f45b835",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55a9b07",
   "metadata": {},
   "source": [
    "First, we'll read in the text and tokenize it into sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa091d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('moby_dick.txt') as fi:\n",
    "    text = fi.read()\n",
    "    \n",
    "sentences = sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ae8d11",
   "metadata": {},
   "source": [
    "First, let's build a simple unigram language model. This will only require us to keep up with the counts of each individual word.\n",
    "\n",
    "For this, let's use a [defaultdict](https://docs.python.org/3/library/collections.html#defaultdict-objects) from the collections module. A behaves very much like a dictionary, but it allows us to specify what happens when we try to access a key which does not yet exist.\n",
    "\n",
    "You might want to check out this page which talks about working with defaultdict objects: https://www.geeksforgeeks.org/defaultdict-in-python/\n",
    "\n",
    "Create a defaultdict named `unigram_model` which contains the count of each word in the text. Do this by iterating through each sentence, tokenizing and then adding the count to unigram_model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d2062c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cb5134",
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_model = defaultdict(int)\n",
    "\n",
    "for sentence in tqdm(sentences): \n",
    "    for word in word_tokenize(sentence):\n",
    "        unigram_model[word] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec696af3",
   "metadata": {},
   "source": [
    "Now, write a function called `unigram_prob` which takes in a word as an argument and returns the probability (based on word counts) of seeing that word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a1a6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffe9427",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unigram_prob(word):\n",
    "    numerator = unigram_model[word]\n",
    "    denominator = sum(unigram_model.values())\n",
    "    return numerator / denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38e9e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_prob('the')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee01af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_prob('whale')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c6677d",
   "metadata": {},
   "source": [
    "Finally, create a function, `random_unigram` that randomly selects a word based on the probabilities above.\n",
    "\n",
    "**Hint:** The [`random.choices` function](https://www.w3schools.com/python/ref_random_choices.asp) might be useful for this task, which allows you to randomly select an element from a list, with the chances of each word specified by a list of weights. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44eb8a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e011f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_unigram():\n",
    "    return random.choices(list(unigram_model.keys()), \n",
    "                          weights = unigram_model.values())[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20b2b9b",
   "metadata": {},
   "source": [
    "Now, we can see what random text generated by your model looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0399be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = []\n",
    "\n",
    "for _ in range(50):\n",
    "    sentence.append(random_unigram())\n",
    "\n",
    "print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1730d1",
   "metadata": {},
   "source": [
    "## Bigram Model\n",
    "\n",
    "Now, let's build a bigram model. This will require us to count how many times each bigram appears. \n",
    "\n",
    "Let's do this by again utilizing a defaultdict, but this time we'll use a nested structure.\n",
    "\n",
    "Create a defaultdict `bigram_model` where the keys are equal to the first word in a bigram and each value is a defaultdict containing counts of the number of times each word is the second part of a bigram starting with the first word.\n",
    "\n",
    "For example, `bigram_model[\"white\"]` would be a defaultdict counting the number of times each word shows up as the second part of a bigram which starts with \"white\". So `bigram_model[\"white\"][\"whale\"]` gives the number of times that \"white whale\" shows up in our text and `bigram_model[\"accursed\"][\"whale\"]` gives the number of times that \"accursed whale\" appears.\n",
    "\n",
    "**Note:** To account for words that appear at the beginning of sentences, add a token `\"<s>\"` at the beginning of each sentence and one `\"</s>\"` at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729ba29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e1a98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_model = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "for sentence in tqdm(sentences):\n",
    "    sentence = [\"<s>\"] + word_tokenize(sentence) + [\"</s>\"]\n",
    "    for first_word, second_word in zip(sentence[:-1], sentence[1:]):\n",
    "        bigram_model[first_word][second_word] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c5000f",
   "metadata": {},
   "source": [
    "Now, write a function `random_bigram` which takes as an argument `seed` (which should default to `\"<s>\"`) and randomly selects a next word based on the bigram probabilities from your bigram model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6b3897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fd0c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_bigram(seed = '<s>'):\n",
    "    return random.choices(list(bigram_model[seed].keys()), \n",
    "                          weights = bigram_model[seed].values())[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa40e69",
   "metadata": {},
   "source": [
    "Now, let's try it out and see how well it creates sentences.\n",
    "\n",
    "Starting with a list containing `['<s>']`, use your `random_bigram` function to add tokens until you have added the `\"</s>\"` token. Then print out the resulting sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e327df1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = ['<s>']\n",
    "\n",
    "# Fill in the code to generate a random sentence\n",
    "\n",
    "print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867d79fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = ['<s>']\n",
    "\n",
    "while sentence[-1] != '</s>':\n",
    "    sentence.append(random_bigram(sentence[-1]))\n",
    "    \n",
    "print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eade22db",
   "metadata": {},
   "source": [
    "**Bonus** Extend your above work to trigram or even higher. What are the disadvantages of 3- or 4-gram models using the current text?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b83ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_model = defaultdict(lambda: defaultdict(lambda: defaultdict(int)))\n",
    "\n",
    "for sentence in tqdm(sentences):\n",
    "    sentence = [\"<s>\", \"<s>\"] + word_tokenize(sentence) + [\"</s>\"]\n",
    "    for first_word, second_word, third_word in zip(sentence[:-2], sentence[1:-1], sentence[2:]):\n",
    "        trigram_model[first_word][second_word][third_word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffcdbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_trigram(seed = ['<s>', '<s>']):\n",
    "    return random.choices(list(trigram_model[seed[0]][seed[1]].keys()), \n",
    "                          weights = trigram_model[seed[0]][seed[1]].values())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c569c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = ['<s>', '<s>']\n",
    "\n",
    "while sentence[-1] != '</s>':\n",
    "    sentence.append(random_trigram(sentence[-2:]))\n",
    "    \n",
    "print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d752130a",
   "metadata": {},
   "outputs": [],
   "source": [
    "quadgram_model = defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: defaultdict(int))))\n",
    "\n",
    "for sentence in tqdm(sentences):\n",
    "    sentence = [\"<s>\", \"<s>\", \"<s>\"] + word_tokenize(sentence) + [\"</s>\"]\n",
    "    for first_word, second_word, third_word, fourth_word in zip(sentence[:-3], \n",
    "                                                   sentence[1:-2],\n",
    "                                                   sentence[2:-1],\n",
    "                                                  sentence[3:]):\n",
    "        quadgram_model[first_word][second_word][third_word][fourth_word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad7a42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_quadgram(seed = ['<s>', '<s>', '<s>']):\n",
    "    return random.choices(list(quadgram_model[seed[0]][seed[1]][seed[2]].keys()), \n",
    "                          weights = quadgram_model[seed[0]][seed[1]][seed[2]].values())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7158fab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = ['<s>', '<s>', '<s>']\n",
    "\n",
    "while sentence[-1] != '</s>':\n",
    "    sentence.append(random_quadgram(sentence[-3:]))\n",
    "print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8212179c",
   "metadata": {},
   "source": [
    "## Using NLTK Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70184adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.lm import MLE, Laplace\n",
    "from nltk.lm.preprocessing import pad_both_ends, padded_everygram_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ca314a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_size = 2\n",
    "\n",
    "paddedLine = [list(pad_both_ends(word_tokenize(sentence), n = ngram_size)) for sentence in sent_tokenize(text)]\n",
    "\n",
    "train, vocab = padded_everygram_pipeline(ngram_size, paddedLine)\n",
    "\n",
    "lm = MLE(ngram_size)\n",
    "\n",
    "lm.fit(train, vocab)\n",
    "\n",
    "print(lm.counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2724e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.perplexity([\"Call\", \"me\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89565912",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = ['<s>']\n",
    "\n",
    "while sentence[-1] != '</s>':\n",
    "    sentence.append(lm.generate(text_seed = sentence))\n",
    "print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e5051e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_size = 3\n",
    "\n",
    "paddedLine = [list(pad_both_ends(word_tokenize(sentence), n = ngram_size)) for sentence in sent_tokenize(moby)]\n",
    "\n",
    "train, vocab = padded_everygram_pipeline(ngram_size, paddedLine)\n",
    "\n",
    "lm = Laplace(ngram_size)\n",
    "\n",
    "lm.fit(train, vocab)\n",
    "\n",
    "print(lm.counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1f63c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = ['<s>', '<s>']\n",
    "\n",
    "while sentence[-1] != '</s>':\n",
    "    sentence.append(lm.generate(text_seed = sentence))\n",
    "print(' '.join(sentence))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
