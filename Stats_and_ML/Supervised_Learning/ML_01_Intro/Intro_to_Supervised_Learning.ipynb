{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Supervised Learning\n",
    "\n",
    "In this notebook, we will explore some of the basic tools and concepts used in machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will be using a synthetic dataset. In this case, we will exactly know the data generation process. The independent values ($X$) come from a uniform distribution between 0 and 1, and the dependent values ($y$) are equal to the sine of $2\\pi X$ plus some noise which comes from a normal distribution with mean 0 and standard deviation 0.2.\n",
    "\n",
    "**Disclaimer:** This is nothing like working with real data, but is just for learning purposes.\n",
    "\n",
    "Of course, when working with real data, we won't know the underlying data generation process, and can only try to make good predictions based off of our limited sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_noisy_sine(size = 50, sigma = 0.2, random_state = None):\n",
    "    if random_state:\n",
    "        np.random.seed(random_state)\n",
    "    \n",
    "    X = np.random.uniform(low = 0, high = 1, size = size)\n",
    "    y = np.sin(2*np.pi*X) + np.random.normal(loc = 0, scale = sigma, size = size)\n",
    "    \n",
    "    X = X.reshape(-1,1)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = generate_noisy_sine(size = 50, random_state = 321)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at our data with a scatterplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,6))\n",
    "plt.scatter(X, y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add the sine function to our scatterplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_grid = np.linspace(start = 0, stop = 1, num = 100).reshape(-1,1)\n",
    "\n",
    "plt.figure(figsize = (10,6))\n",
    "plt.scatter(X, y)\n",
    "plt.plot(x_grid, np.sin(2*np.pi*x_grid), color = 'red', linewidth = 3);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What do you notice when you compare the observed data (the points) to the underlying generation function (the sine curve)?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though it is not the correct model for the data generation process, let's see how well an ordinary linear model does at generating predictions.\n",
    "\n",
    "That is, we'll generate predictions using a function of the form\n",
    "\n",
    "$$\\hat{f}(x) = \\beta_0 + \\beta_1 x$$\n",
    "\n",
    "First, import the LinearRegression class from the linear_model module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then create an instance of this class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, use the fit method, providing the predictor variable and target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now generate predictions using the `predict` method. Let's take advantage of this in order to plot the fit line against the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,6))\n",
    "plt.scatter(X, y)\n",
    "plt.plot(x_grid, linreg.predict(x_grid), color = 'black', linewidth = 2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to see the coefficients, we can access the `intercept_` and `coef_` attributes of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows that our model looks like\n",
    "\n",
    "$$\\hat{f}(x) = 1.1717 - 2.0767x$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How can we interpret the intercept and coefficient values of this model, in terms of the relationship between $x$ and $y$?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can we measure how well our model did? One common metric is the mean squared error.\n",
    "\n",
    "$$\\text{MSE} = \\frac{1}{n}\\sum_{i = 1}^n(\\hat{f}(x_i) - y_i)^2$$\n",
    "\n",
    "Where our dataset is $\\{(x_1, y_1), \\ldots, (x_n, y_n)\\}$, and $\\hat{f}(x_i)$ is the predicted value on $x_i$.\n",
    "\n",
    "What we are doing is averaging the squared residuals, where the residual is the vertical distance between the true value and the predicted value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,6))\n",
    "plt.scatter(X, y)\n",
    "plt.plot(x_grid, linreg.predict(x_grid), color = 'black', linewidth = 2)\n",
    "\n",
    "for x_i,y_i,y_i_hat in zip(X, y, linreg.predict(X)):\n",
    "    plt.plot([x_i,x_i], [y_i, y_i_hat], color = 'red', zorder = -100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean squared error is available from scikit-learn's metrics module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(y, linreg.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we want to use a slightly more complicated model? Clearly a straight line is not going to do a great job, but maybe a degree 2 polynomial will.\n",
    "\n",
    "In order to fit a polynomial, we can make use of the PolynomialFeatures class. Also, we can use a Pipeline to organize our work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a Pipeline, we need to specify a series of steps as a list of tuples. Each tuple should have a name for the step and then either a transformer or a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have created our pipeline, we can fit it just like before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,6))\n",
    "plt.scatter(X, y)\n",
    "plt.plot(x_grid, pipe.predict(x_grid), color = 'black', linewidth = 2)\n",
    "\n",
    "for x_i,y_i,y_i_hat in zip(X, y, pipe.predict(X)):\n",
    "    plt.plot([x_i,x_i], [y_i, y_i_hat], color = 'red', zorder = -100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(y, pipe.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe a degree 3 polynomial would do better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps = [\n",
    "    ('poly', PolynomialFeatures(degree = 3, include_bias = False)),\n",
    "    ('linreg', LinearRegression())\n",
    "])\n",
    "\n",
    "pipe.fit(X, y)\n",
    "\n",
    "plt.figure(figsize = (10,6))\n",
    "plt.scatter(X, y)\n",
    "plt.plot(x_grid, pipe.predict(x_grid), color = 'black', linewidth = 2)\n",
    "for x_i,y_i,y_i_hat in zip(X, y, pipe.predict(X)):\n",
    "    plt.plot([x_i,x_i], [y_i, y_i_hat], color = 'red', zorder = -100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(y, pipe.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do see further improvement. Let's fit a whole range of different degrees and see how the MSEs compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE = {}\n",
    "\n",
    "for degree in range(1, 11):\n",
    "\n",
    "    pipe = Pipeline(steps = [\n",
    "        ('poly', PolynomialFeatures(degree = degree, include_bias = False)),\n",
    "        ('linreg', LinearRegression())\n",
    "    ])\n",
    "\n",
    "    pipe.fit(X, y)\n",
    "    \n",
    "    MSE[degree] = mean_squared_error(y, pipe.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What do you notice?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But wait, if we're builing a model for prediction, we don't care how it does on the data that it has seen - what we care about is **generalization error**. How does it do on unseen data?\n",
    "\n",
    "Since in this case, we have a function to generate new data, we can get a really accurate estimate of the generalization error by generating a really large sample, say 10000 points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_out, y_out = generate_noisy_sine(size = 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can find the MSE for each degree we tested above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE_out = {}\n",
    "\n",
    "for degree in range(1, 11):\n",
    "\n",
    "    pipe = Pipeline(steps = [\n",
    "        ('poly', PolynomialFeatures(degree = degree, include_bias = False)),\n",
    "        ('linreg', LinearRegression())\n",
    "    ])\n",
    "\n",
    "    pipe.fit(X, y)\n",
    "    \n",
    "    MSE_out[degree] = mean_squared_error(y_out, pipe.predict(X_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare the MSE that we observed on the training data to the MSE on unseen data (the generalization error)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,6))\n",
    "\n",
    "plt.scatter(range(1, 11), [MSE_out[i] for i in range(1, 11)], s = 200, \n",
    "            edgecolor = 'black', linewidth = 2, color = 'yellow', label = 'unseen')\n",
    "\n",
    "plt.scatter(range(1, 11), [MSE[i] for i in range(1, 11)], s = 200, \n",
    "            edgecolor = 'black', linewidth = 2, color = 'cornflowerblue', label = 'training')\n",
    "\n",
    "\n",
    "for i in range(1,11):\n",
    "    plt.plot([i,i], [MSE[i], MSE_out[i]], color = 'black', linewidth = 3, zorder = -100)\n",
    "\n",
    "fontsize = 18\n",
    "plt.xlabel('Degree', fontsize = fontsize)\n",
    "plt.ylabel('MSE', fontsize = fontsize)\n",
    "plt.xticks(range(1, 11), fontsize = fontsize)\n",
    "plt.yticks(fontsize = fontsize)\n",
    "\n",
    "plt.legend(fontsize = fontsize - 2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Two things to note:**\n",
    "\n",
    "1. The training MSE is overly optimistic (it is **biased downward**).\n",
    "\n",
    "2. As we increase the degree of the polynomial (the complexity of the model), the training MSE improves, but the MSE on the unseen data drastically increases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What about with a real dataset where we can't call our data generation function to get data?**\n",
    "\n",
    "We can approximate it!\n",
    "\n",
    "One way to approximate is to save some of our data as a test set. We will fit the model only on the remaining training data. Then we can approximate the unseen error using the test set.\n",
    "\n",
    "To create this test set, we can use the train_test_split function from the model_selection module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here  - use random_state = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE_train = {}\n",
    "MSE_test = {}\n",
    "MSE_out = {}\n",
    "\n",
    "for degree in range(1, 11):\n",
    "\n",
    "    pipe = Pipeline(steps = [\n",
    "        ('poly', PolynomialFeatures(degree = degree, include_bias = False)),\n",
    "        ('linreg', LinearRegression())\n",
    "    ])\n",
    "\n",
    "    pipe.fit(X_train, y_train)\n",
    "    \n",
    "    MSE_train[degree] = mean_squared_error(y_train, pipe.predict(X_train))\n",
    "    \n",
    "    MSE_test[degree] = mean_squared_error(y_test, pipe.predict(X_test))\n",
    "    \n",
    "    MSE_out[degree] = mean_squared_error(y_out, pipe.predict(X_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,6))\n",
    "\n",
    "plt.scatter(range(1, 11), [MSE_out[i] for i in range(1, 11)], s = 200, \n",
    "            edgecolor = 'black', linewidth = 2, color = 'yellow', label = 'unseen')\n",
    "\n",
    "plt.scatter(range(1, 11), [MSE_test[i] for i in range(1, 11)], s = 200, \n",
    "            edgecolor = 'black', linewidth = 2, color = 'orange', label = 'test')\n",
    "\n",
    "plt.scatter(range(1, 11), [MSE[i] for i in range(1, 11)], s = 200, \n",
    "            edgecolor = 'black', linewidth = 2, color = 'cornflowerblue', label = 'training')\n",
    "\n",
    "\n",
    "for i in range(1,11):\n",
    "    plt.plot([i,i], [MSE[i], max(MSE_out[i], MSE_test[i])], color = 'black', linewidth = 3, zorder = -100)\n",
    "\n",
    "fontsize = 18\n",
    "plt.xlabel('Degree', fontsize = fontsize)\n",
    "plt.ylabel('MSE', fontsize = fontsize)\n",
    "plt.xticks(range(1, 11), fontsize = fontsize)\n",
    "plt.yticks(fontsize = fontsize)\n",
    "\n",
    "plt.legend(fontsize = fontsize - 2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What do you notice?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Takeaways:** Using a test set can give us an (unbiased) estimate of the error on an unseen set.\n",
    "\n",
    "When I say that the test data is an unbiased estimate of the generalization error, that means that on average it will be correct, but on any given model, it is unlikely to be correct.\n",
    "\n",
    "Let's do a simulation to show that we do in fact get an unbiased estimate from the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE_test_vs_out = []\n",
    "\n",
    "np.random.seed(321)\n",
    "\n",
    "for _ in range(1000):\n",
    "    X, y = generate_noisy_sine(size = 50)\n",
    "    X_out, y_out = generate_noisy_sine(size = 10000)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .25)\n",
    "    \n",
    "    pipe = Pipeline(steps = [\n",
    "        ('poly', PolynomialFeatures(degree = 3, include_bias = False)),\n",
    "        ('linreg', LinearRegression())\n",
    "    ])\n",
    "\n",
    "    pipe.fit(X_train, y_train)\n",
    "    \n",
    "    MSE_test = mean_squared_error(y_test, pipe.predict(X_test))\n",
    "    \n",
    "    MSE_out = mean_squared_error(y_out, pipe.predict(X_out))\n",
    "        \n",
    "    MSE_test_vs_out.append(MSE_test - MSE_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On average, the test error will be equal to the true error. That is, the error on the test set is an **unbiased** estimate of the true error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(MSE_test_vs_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, there is some variance since the test set is only a small sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(MSE_test_vs_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why?** Think about it like estimating the mean of a population from a sample. The standard error is inversely proportional to the root of the sample size."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
