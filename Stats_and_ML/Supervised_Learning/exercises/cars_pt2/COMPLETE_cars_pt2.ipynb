{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc2862e8",
   "metadata": {},
   "source": [
    "## Regularized Regression\n",
    "In this notebook, you'll be working with data on cars from the year 2010 with the goal being to see how well you can predict the fuel economy based on the other variables that you have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcb28ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression, RidgeCV, LassoCV, Lasso, ElasticNetCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, PolynomialFeatures, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_selection import VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5c5dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cars = pd.read_csv('data/cars_2010.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16aa38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cars.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83a9f49",
   "metadata": {},
   "source": [
    "Let's start with a baseline model which uses only EngDispl and EngDispl^2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbe092a",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['EngDispl']\n",
    "\n",
    "X = cars[variables]\n",
    "y = cars['FE']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 321)\n",
    "\n",
    "pipe = Pipeline(steps = [\n",
    "    ('pf', PolynomialFeatures(include_bias=False, interaction_only=False, degree = 2)),\n",
    "    ('linreg', LinearRegression())\n",
    "])\n",
    "\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ac7350",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(pipe['pf'].get_feature_names_out(variables))\n",
    "\n",
    "coefficients = pd.DataFrame({\n",
    "    'variable': ['intercept'] + features,\n",
    "    'coefficient': [pipe['linreg'].intercept_] + list(pipe['linreg'].coef_)\n",
    "})\n",
    "coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b5c345",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'MSE: {mean_squared_error(y_test, pipe.predict(X_test))}')\n",
    "print(f'R2: {r2_score(y_test, pipe.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4038f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cars.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac1d1de",
   "metadata": {},
   "source": [
    "Now, let's add in all other features to see how much of an improvement we can get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83460cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = [x for x in cars.columns if x != 'FE']\n",
    "categorical_variables = ['Transmission', 'AirAspirationMethod', 'DriveDesc', 'CarlineClassDesc']\n",
    "\n",
    "X = cars[variables]\n",
    "y = cars['FE']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 321)\n",
    "\n",
    "pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('ct', ColumnTransformer(\n",
    "            transformers = [\n",
    "                ('ohe', OneHotEncoder(sparse = False, drop = 'first'), categorical_variables)\n",
    "            ],\n",
    "            remainder = 'passthrough')),\n",
    "        ('pf', PolynomialFeatures(interaction_only = True, include_bias = False)),\n",
    "        ('vt', VarianceThreshold()),\n",
    "        ('linreg', LinearRegression())\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5969c12",
   "metadata": {},
   "source": [
    "First, look at the performance on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00e2f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'MSE: {mean_squared_error(y_train, pipe.predict(X_train))}')\n",
    "print(f'R2: {r2_score(y_train, pipe.predict(X_train))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0ab7b6",
   "metadata": {},
   "source": [
    "Now, on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50201729",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'MSE: {mean_squared_error(y_test, pipe.predict(X_test))}')\n",
    "print(f'R2: {r2_score(y_test, pipe.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ebb01c",
   "metadata": {},
   "source": [
    "**Question 1:** How do interpret the R^2 value that we got?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c1e18f",
   "metadata": {},
   "source": [
    "**Question 2:** Why might the model be peforming so poorly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aea9b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(pipe['ct'].named_transformers_['ohe'].get_feature_names_out(categorical_variables))\n",
    "features += [x for x in X_train.columns if x not in categorical_variables]\n",
    "features = list(pipe['pf'].get_feature_names_out(features))\n",
    "features = list(np.array(features)[pipe['vt'].get_support()])\n",
    "\n",
    "coefficients = pd.DataFrame({\n",
    "    'variable': ['intercept'] + features,\n",
    "    'coefficient': [pipe['linreg'].intercept_] + list(pipe['linreg'].coef_)\n",
    "})\n",
    "\n",
    "coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b762f525",
   "metadata": {},
   "source": [
    "**Question 3:** Explore the coefficients that you get. Does anything appear suspect?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc085408",
   "metadata": {},
   "source": [
    "Now, let's switch to ridge regression to see how it changes our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ea703e",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = [x for x in cars.columns if x != 'FE']\n",
    "categorical_variables = ['Transmission', 'AirAspirationMethod', 'DriveDesc', 'CarlineClassDesc']\n",
    "\n",
    "X = cars[variables]\n",
    "y = cars['FE']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 321)\n",
    "\n",
    "pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('ct', ColumnTransformer(\n",
    "            transformers = [\n",
    "                ('ohe', OneHotEncoder(sparse = False,\n",
    "                                      #drop = 'first',\n",
    "                                      handle_unknown = 'ignore',\n",
    "                                  \n",
    "                                     ), categorical_variables)\n",
    "            ],\n",
    "            remainder = 'passthrough')),\n",
    "        ('pf', PolynomialFeatures(interaction_only = False, include_bias = False)),\n",
    "        ('vt', VarianceThreshold()),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('linreg', RidgeCV())\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eaefd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'MSE: {mean_squared_error(y_train, pipe.predict(X_train))}')\n",
    "print(f'R2: {r2_score(y_train, pipe.predict(X_train))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954613fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'MSE: {mean_squared_error(y_test, pipe.predict(X_test))}')\n",
    "print(f'R2: {r2_score(y_test, pipe.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a01a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(pipe['ct'].named_transformers_['ohe'].get_feature_names_out(categorical_variables))\n",
    "features += [x for x in X_train.columns if x not in categorical_variables]\n",
    "features = list(pipe['pf'].get_feature_names_out(features))\n",
    "features = list(np.array(features)[pipe['vt'].get_support()])\n",
    "\n",
    "coefficients = pd.DataFrame({\n",
    "    'variable': ['intercept'] + features,\n",
    "    'coefficient': [pipe['linreg'].intercept_] + list(pipe['linreg'].coef_)\n",
    "})\n",
    "\n",
    "coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62140692",
   "metadata": {},
   "source": [
    "**Question 4:** What value of alpha did the model decide on? (Hint: this is a fit attribute of the model. You might want to look at the [RidgeCV documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeCV.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715e795d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe['linreg'].alpha_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22dfc21",
   "metadata": {},
   "source": [
    "**Question 5: True or False -** A smaller value of alpha will tend to result in smaller coefficient values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3179e7e7",
   "metadata": {},
   "source": [
    "**Question 6:** By default, the RidgeCV model will only try out 3 different values for alpha - 0.1, 1, and 10. Modify the code below and try out a larger range of alpha values. Can you find a better model? What is the best value of alpha that you can find?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6325d162",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = [x for x in cars.columns if x != 'FE']\n",
    "categorical_variables = ['Transmission', 'AirAspirationMethod', 'DriveDesc', 'CarlineClassDesc']\n",
    "\n",
    "X = cars[variables]\n",
    "y = cars['FE']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 321)\n",
    "\n",
    "pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('ct', ColumnTransformer(\n",
    "            transformers = [\n",
    "                ('ohe', OneHotEncoder(sparse = False,\n",
    "                                      #drop = 'first',\n",
    "                                      handle_unknown = 'ignore',\n",
    "                                  \n",
    "                                     ), categorical_variables)\n",
    "            ],\n",
    "            remainder = 'passthrough')),\n",
    "        ('pf', PolynomialFeatures(interaction_only = False, include_bias = False)),\n",
    "        ('vt', VarianceThreshold()),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('linreg', RidgeCV(alphas = (10, 50, 100)))\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa75b858",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe['linreg'].alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da319754",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'MSE: {mean_squared_error(y_test, pipe.predict(X_test))}')\n",
    "print(f'R2: {r2_score(y_test, pipe.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8824b1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(pipe['ct'].named_transformers_['ohe'].get_feature_names_out(categorical_variables))\n",
    "features += [x for x in X_train.columns if x not in categorical_variables]\n",
    "features = list(pipe['pf'].get_feature_names_out(features))\n",
    "features = list(np.array(features)[pipe['vt'].get_support()])\n",
    "\n",
    "coefficients = pd.DataFrame({\n",
    "    'variable': ['intercept'] + features,\n",
    "    'coefficient': [pipe['linreg'].intercept_] + list(pipe['linreg'].coef_)\n",
    "})\n",
    "\n",
    "coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4972b2f9",
   "metadata": {},
   "source": [
    "Finally, let's try out a lasso model. Notice that we have increased the `max_iter` value so that it has a good chance on converging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec7f98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = [x for x in cars.columns if x != 'FE']\n",
    "categorical_variables = ['Transmission', 'AirAspirationMethod', 'DriveDesc', 'CarlineClassDesc']\n",
    "\n",
    "X = cars[variables]\n",
    "y = cars['FE']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 321)\n",
    "\n",
    "pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('ct', ColumnTransformer(\n",
    "            transformers = [\n",
    "                ('ohe', OneHotEncoder(sparse = False, drop = 'first'), categorical_variables)\n",
    "            ],\n",
    "            remainder = 'passthrough')),\n",
    "        ('pf', PolynomialFeatures(interaction_only = False, include_bias = False)),\n",
    "        ('vt', VarianceThreshold()),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('linreg', LassoCV( max_iter = 5000))\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4fe081",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'MSE: {mean_squared_error(y_test, pipe.predict(X_test))}')\n",
    "print(f'R2: {r2_score(y_test, pipe.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb0cf6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(pipe['ct'].named_transformers_['ohe'].get_feature_names_out(categorical_variables))\n",
    "features += [x for x in X_train.columns if x not in categorical_variables]\n",
    "features = list(pipe['pf'].get_feature_names_out(features))\n",
    "features = list(np.array(features)[pipe['vt'].get_support()])\n",
    "\n",
    "coefficients = pd.DataFrame({\n",
    "    'variable': ['intercept'] + features,\n",
    "    'coefficient': [pipe['linreg'].intercept_] + list(pipe['linreg'].coef_)\n",
    "})\n",
    "\n",
    "coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1091645",
   "metadata": {},
   "source": [
    "**Question 7:** What proportion of coefficients end up being zero?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc24550e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(coefficients['coefficient'] == 0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6764c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients[coefficients['coefficient'] != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ba7070",
   "metadata": {},
   "source": [
    "Finally, let's use the Lasso class so that we can manually set the value of alpha to see the effect on the model.\n",
    "\n",
    "**Question 8:** What seems to be the relationship between alpha and the performance of the model? on the number of nonzero coefficients?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6bd1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = [x for x in cars.columns if x != 'FE']\n",
    "categorical_variables = ['Transmission', 'AirAspirationMethod', 'DriveDesc', 'CarlineClassDesc']\n",
    "\n",
    "X = cars[variables]\n",
    "y = cars['FE']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 321)\n",
    "\n",
    "pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('ct', ColumnTransformer(\n",
    "            transformers = [\n",
    "                ('ohe', OneHotEncoder(sparse = False, drop = 'first'), categorical_variables)\n",
    "            ],\n",
    "            remainder = 'passthrough')),\n",
    "        ('pf', PolynomialFeatures(interaction_only = False, include_bias = False)),\n",
    "        ('vt', VarianceThreshold()),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('linreg', Lasso( alpha = 0.5))\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "print(f'MSE: {mean_squared_error(y_test, pipe.predict(X_test))}')\n",
    "print(f'R2: {r2_score(y_test, pipe.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e2ca74",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(pipe['ct'].named_transformers_['ohe'].get_feature_names_out(categorical_variables))\n",
    "features += [x for x in X_train.columns if x not in categorical_variables]\n",
    "features = list(pipe['pf'].get_feature_names_out(features))\n",
    "features = list(np.array(features)[pipe['vt'].get_support()])\n",
    "\n",
    "coefficients = pd.DataFrame({\n",
    "    'variable': ['intercept'] + features,\n",
    "    'coefficient': [pipe['linreg'].intercept_] + list(pipe['linreg'].coef_)\n",
    "})\n",
    "\n",
    "coefficients\n",
    "\n",
    "coefficients[np.abs(coefficients['coefficient']) > 0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
