{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "greater-dance",
   "metadata": {},
   "source": [
    "# Introduction to Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pediatric-excitement",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import LinearRegression, RidgeCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "royal-effort",
   "metadata": {},
   "source": [
    "Let's return to the King County housing dataset for this exercise.\n",
    "\n",
    "We'll start by doing the standard feature creation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numeric-charleston",
   "metadata": {},
   "outputs": [],
   "source": [
    "kc = pd.read_csv('data/kc_house_data.csv')\n",
    "\n",
    "X = kc[['date', 'bedrooms', 'bathrooms', 'sqft_living',\n",
    "       'sqft_lot', 'floors', 'waterfront', 'view', 'condition', 'grade',\n",
    "       'sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated', 'zipcode',\n",
    "       'lat', 'long', 'sqft_living15', 'sqft_lot15']].copy()\n",
    "y = kc['price']\n",
    "\n",
    "X['date'] = pd.to_datetime(X['date'])\n",
    "X['sales_year'] = X['date'].dt.year\n",
    "\n",
    "X['age_at_sale'] = X['sales_year'] - X['yr_built']\n",
    "X['years_since_renovation'] = X['sales_year'] - np.max(X[['yr_built', 'yr_renovated']], axis = 1)\n",
    "\n",
    "\n",
    "X = X.drop(columns = ['date', 'sales_year', 'yr_built', 'yr_renovated'])\n",
    "\n",
    "X = pd.get_dummies(X, columns = ['zipcode'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 321)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thousand-sector",
   "metadata": {},
   "source": [
    "Let's start by just making a basic linear regression model with minimal preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "municipal-thanksgiving",
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "print(f'R2 Score: {r2_score(y_test, linreg.predict(X_test))}')\n",
    "print(f'MAE: {mean_absolute_error(y_test, linreg.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125fc60a",
   "metadata": {},
   "source": [
    "And for comparison, we'll do a ridge regression model as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concrete-texas",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('scale', StandardScaler()),\n",
    "        ('linreg', RidgeCV())\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "print(f'R2 Score: {r2_score(y_test, ridge.predict(X_test))}')\n",
    "print(f'MAE: {mean_absolute_error(y_test, ridge.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8835a7",
   "metadata": {},
   "source": [
    "Home prices tend to be very skewed, and these are no different. It may be advantageous to transform the target before fitting our model so that it pays less attention to the extreme-priced homes. We can try using the logarithm to transform these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c336b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.hist()\n",
    "plt.title('Untransformed');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecee828",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log(y_train).hist()\n",
    "plt.title('Transformed');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3aff120",
   "metadata": {},
   "source": [
    "If we want to apply a transformation to the target variable, the best way to do this so that we are making fair evaluations is to use a TransformedTargetRegressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bf87f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import TransformedTargetRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e78c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('scale', StandardScaler()),\n",
    "        ('linreg', RidgeCV())\n",
    "    ]\n",
    ")\n",
    "\n",
    "ttr = TransformedTargetRegressor(\n",
    "    regressor = pipe,\n",
    "    func = np.log,\n",
    "    inverse_func = np.exp\n",
    ")\n",
    "\n",
    "ttr.fit(X_train, y_train)\n",
    "\n",
    "print(f'R2 Score: {r2_score(y_test, ttr.predict(X_test))}')\n",
    "print(f'MAE: {mean_absolute_error(y_test, ttr.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96060c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_zips = [x for x in X_train.columns if 'zipcode' not in x]\n",
    "non_zips\n",
    "\n",
    "X_train[non_zips].skew().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34872602",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_columns = ['sqft_living', 'sqft_lot', 'bedrooms', \n",
    "                                               'sqft_basement', 'sqft_above', 'sqft_living', 'sqft_living15']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fe3f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import PowerTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b491c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('ct', ColumnTransformer(\n",
    "            transformers = [\n",
    "                ('power', PowerTransformer(), transformed_columns)\n",
    "            ],\n",
    "            remainder = 'passthrough'\n",
    "        )),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('linear', RidgeCV())\n",
    "    ]\n",
    ")\n",
    "\n",
    "ttr = TransformedTargetRegressor(\n",
    "    regressor = pipe,\n",
    "    func = np.log,\n",
    "    inverse_func = np.exp\n",
    ")\n",
    "\n",
    "ttr.fit(X_train, y_train)\n",
    "\n",
    "print(f'R2 Score: {r2_score(y_test, ttr.predict(X_test))}')\n",
    "print(f'MAE: {mean_absolute_error(y_test, ttr.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed296a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('ct', ColumnTransformer(\n",
    "            transformers = [\n",
    "                ('power', PowerTransformer(), transformed_columns)\n",
    "            ],\n",
    "            remainder = 'passthrough'\n",
    "        )),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('linear', RidgeCV(alphas = [10, 15, 20]))\n",
    "    ]\n",
    ")\n",
    "\n",
    "ttr = TransformedTargetRegressor(\n",
    "    regressor = pipe,\n",
    "    func = np.log,\n",
    "    inverse_func = np.exp\n",
    ")\n",
    "\n",
    "ttr.fit(X_train, y_train)\n",
    "\n",
    "print(f'R2 Score: {r2_score(y_test, ttr.predict(X_test))}')\n",
    "print(f'MAE: {mean_absolute_error(y_test, ttr.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84eeb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "ttr.regressor_['linear'].alpha_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da8f343",
   "metadata": {},
   "source": [
    "Now that we've gotten some baseline scores, let's see how we do using a neural network.\n",
    "\n",
    "Because of the way that neural networks optimize their coefficients, it is useful to scale your variable values. In this case, we'll go with a MinMaxScaler, which will convert all variables to values between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e174fbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a074ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('scaler', MinMaxScaler()),\n",
    "        ('mlr', MLPRegressor(verbose = True))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006166b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1090cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'R2 Score: {r2_score(y_test, pipe.predict(X_test))}')\n",
    "print(f'MAE: {mean_absolute_error(y_test, pipe.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b5da25",
   "metadata": {},
   "source": [
    "You very likely got a ConvergenceWarning, which indicated that the model thinks that it is not yet at a local minimum. You could up the max_iter value or you could take a different approach - add more layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15ae06b",
   "metadata": {},
   "source": [
    "Let's try adding a few layers to see if it improves the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab12e850",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('scaler', MinMaxScaler()),\n",
    "        ('mlr', MLPRegressor(verbose = True,\n",
    "                            hidden_layer_sizes = (100, 100, 100)))\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfb2085",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'R2: {r2_score(y_test, pipe.predict(X_test))}')\n",
    "\n",
    "print(f'MAE: {mean_absolute_error(y_test, pipe.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fdb70e",
   "metadata": {},
   "source": [
    "If you look at the documentation, you'll see that there is a regularization parameter, alpha, that you can experiment with. Let's see what happens if we up the regularization strength."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220cd4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('scaler', MinMaxScaler()),\n",
    "        ('mlr', MLPRegressor(verbose = True,\n",
    "                            hidden_layer_sizes = (100, 100, 100),\n",
    "                            alpha = 1))\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02529036",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'R2: {r2_score(y_test, pipe.predict(X_test))}')\n",
    "\n",
    "print(f'MAE: {mean_absolute_error(y_test, pipe.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5b6668",
   "metadata": {},
   "source": [
    "**Your Turn:** Experiment with the neural network model. By adjusting the number of width of hidden layers, regularization strength, variable transfomations, or number of iterations, can you find a model that does significantly better than a simple ridge regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca9ad45",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('scaler', MinMaxScaler()),\n",
    "        ('mlr', MLPRegressor(verbose = True,\n",
    "                            hidden_layer_sizes = (100, 100, 100),\n",
    "                            alpha = 10,\n",
    "                            max_iter = 1000))\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c766d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'R2: {r2_score(y_test, pipe.predict(X_test))}')\n",
    "\n",
    "print(f'MAE: {mean_absolute_error(y_test, pipe.predict(X_test))}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
