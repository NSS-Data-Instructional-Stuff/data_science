{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e44bceb3",
   "metadata": {},
   "source": [
    "# Adding Interactions using scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b716b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e53883",
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins = pd.read_csv('data/penguins.csv').dropna().reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b18ddad",
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins[['species', 'bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'sex', 'body_mass_g']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431efcce",
   "metadata": {},
   "source": [
    "Let's start by building a model using the species and sex variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab57930",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['flipper_length_mm', 'species', 'sex']\n",
    "categorical_variables = ['species', 'sex']\n",
    "\n",
    "X = penguins[variables]\n",
    "y = penguins['body_mass_g']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 321, stratify = penguins['species'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a380ac2",
   "metadata": {},
   "source": [
    "We need to convert the categorical variables into dummy columns. To dummyize in a way that will work will with other scikit-learn tools, we can use the OneHotEncoder class from scikit-learn's preprocessing module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fad608c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4e94aa",
   "metadata": {},
   "source": [
    "By default, this class returns a sparse matrix. We're going to set sparse to False so that it returns a regular array.\n",
    "\n",
    "We'll also tell it to drop the first category that it sees so that we end up with one fewer column than category.\n",
    "\n",
    "Notice that we have to pass in just the categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c9500b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(sparse = False, drop = 'first')\n",
    "ohe.fit(X_train[categorical_variables])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8245c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe.transform(X_train[categorical_variables])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad8e9d8",
   "metadata": {},
   "source": [
    "If we want to get the resulting column names, we can do so using the `get_feature_names` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4935be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe.get_feature_names_out(categorical_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2716c07",
   "metadata": {},
   "source": [
    "Now, what about our numeric variables? In order to be able to apply one-hot-encoding to some but not all of the columns, we can use the ColumnTransformer class.\n",
    "\n",
    "The ColumnTransformer class lets us specify one or more transformations to apply to subsets of our columns.\n",
    "\n",
    "In this case, we want to dummyize our categorical variables and leave everything else untouched. We'll tell it to do this by specifying to \"passthrough\" the remaining columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff754ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be04c60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = ColumnTransformer(transformers = [\n",
    "    ('ohe', OneHotEncoder(sparse = False, drop = 'first'), categorical_variables)\n",
    "],\n",
    "                      remainder = 'passthrough')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0daa2419",
   "metadata": {},
   "source": [
    "Notice that it outputs the dummy columns first followed by the remaining columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0528beed",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043afd7f",
   "metadata": {},
   "source": [
    "We can extract out the OneHotEncoder using the named_transformers_ attribute of our column transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1195c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct.named_transformers_['ohe'].get_feature_names_out(categorical_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79afd0aa",
   "metadata": {},
   "source": [
    "Finally, we can combine this all together with our LinearRegression model using a Pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c6edc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e89718f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('ct', ColumnTransformer(transformers = [\n",
    "            ('ohe', OneHotEncoder(sparse = False, drop = 'first'), categorical_variables)\n",
    "        ],\n",
    "                                 remainder = 'passthrough')),\n",
    "        ('linreg', LinearRegression())\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4aa3adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'MSE: {mean_squared_error(y_test, pipe.predict(X_test))}')\n",
    "print(f'R2: {r2_score(y_test, pipe.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20472c43",
   "metadata": {},
   "source": [
    "If we want to inspect the coefficients, we have to do a little bit of work to extact out the column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91657737",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(pipe['ct'].named_transformers_['ohe'].get_feature_names_out(categorical_variables))\n",
    "features += [x for x in X_train.columns if x not in categorical_variables]\n",
    "\n",
    "coefficients = pd.DataFrame({\n",
    "    'variable': ['intercept'] + features,\n",
    "    'coefficient': [pipe['linreg'].intercept_] + list(pipe['linreg'].coef_)\n",
    "})\n",
    "coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f009585d",
   "metadata": {},
   "source": [
    "**Question:** What does this model predict for a female Adelie penguin with a flipper length of 189 mm?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4eec29",
   "metadata": {},
   "source": [
    "Now, let's add some interaction terms. We can do this using the PolynomialFeatures class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a85f5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9898c275",
   "metadata": {},
   "source": [
    "The PolynomialFeatures class will create new featues by multiplying our existing variables. For now, we'll specify `interaction_only = True` which let's it know that we don't want to multiply a column by itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a4b852",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('ct', ColumnTransformer(transformers = [\n",
    "            ('ohe', OneHotEncoder(sparse = False, drop = 'first'), categorical_variables)\n",
    "        ],\n",
    "                                 remainder = 'passthrough')),\n",
    "        ('pf', PolynomialFeatures(interaction_only = True, include_bias = False)),\n",
    "        ('linreg', LinearRegression())\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "print(f'MSE: {mean_squared_error(y_test, pipe.predict(X_test))}')\n",
    "print(f'R2: {r2_score(y_test, pipe.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56e9824",
   "metadata": {},
   "source": [
    "Similar to the OneHotEncoder, the PolynomialFeatures class has a `get_feature_names` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d617496",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(pipe['ct'].named_transformers_['ohe'].get_feature_names_out(categorical_variables))\n",
    "features += [x for x in X_train.columns if x not in categorical_variables]\n",
    "features = list(pipe['pf'].get_feature_names_out(features))\n",
    "\n",
    "coefficients = pd.DataFrame({\n",
    "    'variable': ['intercept'] + features,\n",
    "    'coefficient': [pipe['linreg'].intercept_] + list(pipe['linreg'].coef_)\n",
    "})\n",
    "coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ae216f",
   "metadata": {},
   "source": [
    "Notice that we have a column for species_Chinstrap * species_Gentoo. Since a penguin cannot be both Chinstrap and Gentoo, so this column is unnecessary. We can exclude it by using a VarianceThreshold, which will remove any columns that have variance 0 (or below whatever threshold we set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d41fb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90410f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('ct', ColumnTransformer(transformers = [\n",
    "            ('ohe', OneHotEncoder(sparse = False, drop = 'first'), categorical_variables)\n",
    "        ],\n",
    "                                 remainder = 'passthrough')),\n",
    "        ('pf', PolynomialFeatures(interaction_only = True, include_bias = False)),\n",
    "        ('vt', VarianceThreshold()),\n",
    "        ('linreg', LinearRegression())\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "print(f'MSE: {mean_squared_error(y_test, pipe.predict(X_test))}')\n",
    "print(f'R2: {r2_score(y_test, pipe.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d462e033",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(pipe['ct'].named_transformers_['ohe'].get_feature_names_out(categorical_variables))\n",
    "features += [x for x in X_train.columns if x not in categorical_variables]\n",
    "features = list(pipe['pf'].get_feature_names_out(features))\n",
    "features = list(np.array(features)[pipe['vt'].get_support()])\n",
    "\n",
    "coefficients = pd.DataFrame({\n",
    "    'variable': ['intercept'] + features,\n",
    "    'coefficient': [pipe['linreg'].intercept_] + list(pipe['linreg'].coef_)\n",
    "})\n",
    "coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e6b340",
   "metadata": {},
   "source": [
    "**Question:** What does this model predict for a male Adelie penguin with a flipper length of 194 mm?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3865d348",
   "metadata": {},
   "source": [
    "Now, let's add some additional features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746be7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'species', 'sex']\n",
    "categorical_variables = ['species', 'sex']\n",
    "\n",
    "X = penguins[variables]\n",
    "y = penguins['body_mass_g']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 321, stratify = penguins['species'])\n",
    "\n",
    "\n",
    "pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('ct', ColumnTransformer(transformers = [\n",
    "            ('ohe', OneHotEncoder(sparse = False, drop = 'first'), categorical_variables)\n",
    "        ],\n",
    "                                 remainder = 'passthrough')),\n",
    "        ('pf', PolynomialFeatures(interaction_only = True, include_bias = False)),\n",
    "        ('vt', VarianceThreshold()),\n",
    "        ('linreg', LinearRegression())\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "print(f'MSE: {mean_squared_error(y_test, pipe.predict(X_test))}')\n",
    "print(f'R2: {r2_score(y_test, pipe.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63220766",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(pipe['ct'].named_transformers_['ohe'].get_feature_names_out(categorical_variables))\n",
    "features += [x for x in X_train.columns if x not in categorical_variables]\n",
    "features = list(pipe['pf'].get_feature_names_out(features))\n",
    "features = list(np.array(features)[pipe['vt'].get_support()])\n",
    "\n",
    "coefficients = pd.DataFrame({\n",
    "    'variable': ['intercept'] + features,\n",
    "    'coefficient': [pipe['linreg'].intercept_] + list(pipe['linreg'].coef_)\n",
    "})\n",
    "coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08c5c2b",
   "metadata": {},
   "source": [
    "We can also add higher-degree terms using the PolynomialFeatures class by specifying `interaction_only = False`.\n",
    "Notice, however, that we get a significantly more complex model for not a lot of gain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9da2f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('ct', ColumnTransformer(transformers = [\n",
    "            ('ohe', OneHotEncoder(sparse = False, drop = 'first'), categorical_variables)\n",
    "        ],\n",
    "                                 remainder = 'passthrough')),\n",
    "        ('pf', PolynomialFeatures(interaction_only = False, include_bias = False)),\n",
    "        ('vt', VarianceThreshold()),\n",
    "        ('linreg', LinearRegression())\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "print(f'MSE: {mean_squared_error(y_test, pipe.predict(X_test))}')\n",
    "print(f'R2: {r2_score(y_test, pipe.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1ef193",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(pipe['ct'].named_transformers_['ohe'].get_feature_names_out(categorical_variables))\n",
    "features += [x for x in X_train.columns if x not in categorical_variables]\n",
    "features = list(pipe['pf'].get_feature_names_out(features))\n",
    "features = list(np.array(features)[pipe['vt'].get_support()])\n",
    "\n",
    "coefficients = pd.DataFrame({\n",
    "    'variable': ['intercept'] + features,\n",
    "    'coefficient': [pipe['linreg'].intercept_] + list(pipe['linreg'].coef_)\n",
    "})\n",
    "coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62943b8",
   "metadata": {},
   "source": [
    "Notice that, annoyingly, this also includes the one-hot encoded features and their squares. There is not an easy way to remove them, but notice that the value of the coefficients are split between the regular and square columns. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
