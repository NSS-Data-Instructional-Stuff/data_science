{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec593f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, PolynomialFeatures, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c2a9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins = pd.read_csv('data/penguins.csv').dropna().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768908e4",
   "metadata": {},
   "source": [
    "Let's start with a regular linear regression model including all of our predictors and interaction terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f0e0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g', 'sex']\n",
    "categorical_variables = ['sex']\n",
    "\n",
    "X = penguins[variables]\n",
    "y = penguins['species']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 321, stratify = y)\n",
    "\n",
    "pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('ct', ColumnTransformer(\n",
    "            transformers = [\n",
    "                ('ohe', OneHotEncoder(sparse = False, drop = 'first'), categorical_variables)\n",
    "            ],\n",
    "            remainder = 'passthrough')),\n",
    "        ('pf', PolynomialFeatures(interaction_only = True, include_bias = False)),\n",
    "        ('vt', VarianceThreshold()),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('logistic', LogisticRegression())\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90438825",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(pipe['ct'].named_transformers_['ohe'].get_feature_names(categorical_variables))\n",
    "features += [x for x in X_train.columns if x not in categorical_variables]\n",
    "features = pipe['pf'].get_feature_names(features)\n",
    "features = list(np.array(features)[pipe['vt'].get_support()])\n",
    "\n",
    "species = 'Chinstrap'\n",
    "idx = list(pipe['logistic'].classes_).index(species)\n",
    "\n",
    "coefficients = pd.DataFrame({\n",
    "    'variable': ['intercept'] + features,\n",
    "    'coefficient': [pipe['logistic'].intercept_[idx]] + list(pipe['logistic'].coef_[idx])\n",
    "})\n",
    "\n",
    "coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d156df",
   "metadata": {},
   "source": [
    "Let's say that we want to use a lasso model so that we can get a simpler model. There is not a separate lasso classification model, but we can instead change the arguments to the LogisticRegression model. See the documentation for more information: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "\n",
    "We need to change the penalty argument from the default of 'l2' (for ridge) to 'l1' (for lasso). We also have to change the solver that is used.\n",
    "\n",
    "Notice also that we need to scale our variables before passing them to the model. We'll do this with a StandardScaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f5f0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g', 'sex']\n",
    "categorical_variables = ['sex']\n",
    "\n",
    "X = penguins[variables]\n",
    "y = penguins['species']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 321, stratify = y)\n",
    "\n",
    "pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('ct', ColumnTransformer(\n",
    "            transformers = [\n",
    "                ('ohe', OneHotEncoder(sparse = False, drop = 'first'), categorical_variables)\n",
    "            ],\n",
    "            remainder = 'passthrough')),\n",
    "        ('pf', PolynomialFeatures(interaction_only = True, include_bias = False)),\n",
    "        ('vt', VarianceThreshold()),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('logistic', LogisticRegression(penalty = 'l1', solver = 'saga', max_iter = 10000))\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec736de4",
   "metadata": {},
   "source": [
    "We end up with a fairly simple model using just the default penalty of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ec2287",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(pipe['ct'].named_transformers_['ohe'].get_feature_names(categorical_variables))\n",
    "features += [x for x in X_train.columns if x not in categorical_variables]\n",
    "features = pipe['pf'].get_feature_names(features)\n",
    "features = list(np.array(features)[pipe['vt'].get_support()])\n",
    "\n",
    "species = 'Chinstrap'\n",
    "idx = list(pipe['logistic'].classes_).index(species)\n",
    "\n",
    "coefficients = pd.DataFrame({\n",
    "    'variable': ['intercept'] + features,\n",
    "    'coefficient': [pipe['logistic'].intercept_[idx]] + list(pipe['logistic'].coef_[idx])\n",
    "})\n",
    "\n",
    "coefficients[coefficients['coefficient'] != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30bde92",
   "metadata": {},
   "source": [
    "It might be the case that the default value of C is not the best possible one.\n",
    "\n",
    "If we wanted to try out other values, we should use k-fold cross-validation. We can do that using the GridSearchCV class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7cdbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2dffc7",
   "metadata": {},
   "source": [
    "For this, we need to give it the estimator and a grid of hyperparameter values to try out. This grid needs to be a dictionary where the keys specify the hyperparameter and the values are a list of values to try out.\n",
    "\n",
    "You can also specify how you want to score each hyperparameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ffe88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GridSearchCV(estimator = pipe, \n",
    "                 param_grid = {'logistic__C': [1, 0.5, 0.1, 0.05, 0.01]},\n",
    "                 scoring = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06851b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3035f2ba",
   "metadata": {},
   "source": [
    "After fitting, we can see the best parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40318aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d175320",
   "metadata": {},
   "source": [
    "If we need to view additional information, we can access the `best_estimator_` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5108832d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f427db",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(pipe['ct'].named_transformers_['ohe'].get_feature_names(categorical_variables))\n",
    "features += [x for x in X_train.columns if x not in categorical_variables]\n",
    "features = pipe['pf'].get_feature_names(features)\n",
    "features = list(np.array(features)[pipe['vt'].get_support()])\n",
    "\n",
    "\n",
    "species = 'Gentoo'\n",
    "idx = list(pipe['logistic'].classes_).index(species)\n",
    "\n",
    "coefficients = pd.DataFrame({\n",
    "    'variable': ['intercept'] + features,\n",
    "    'coefficient': [gs.best_estimator_['logistic'].intercept_[idx]] + list(gs.best_estimator_['logistic'].coef_[idx])\n",
    "})\n",
    "\n",
    "coefficients[coefficients['coefficient'] != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156cba84",
   "metadata": {},
   "source": [
    "We can generate predictions using the `predict` method of the GridSearchCV object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a940f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, gs.predict(X_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
