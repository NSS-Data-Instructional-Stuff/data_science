{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2a76b10",
   "metadata": {},
   "source": [
    "After completing this exercise, students should be able to:\n",
    "1. Apply the k-means algorithm to identify clusters in a dataset.\n",
    "2. Construct and utilize a scikit-learn Pipeline in order to fit a multistage model.\n",
    "3. Identify hyperparameters used by a model.\n",
    "4. Apply a metric for model evaluation.\n",
    "5. Recognize an attribute that is calculated when calling the .fit() method on a scikit-learn model.\n",
    "6. Using manual iteration to optimize a hyperparameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44014833",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49900aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the dataset and remove rows with missing values\n",
    "\n",
    "penguins = pd.read_csv('data/penguins.csv').dropna().reset_index(drop = True)\n",
    "\n",
    "penguins.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f4b851",
   "metadata": {},
   "source": [
    "In this notebook, we'll focus exclusively on the numeric variables contained in this dataset. If you are interested in seeing how to apply clustering methods to datasets with categorical variables, see the k-modes or k-prototypes algorithms (described here http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.15.4028&rep=rep1&type=pdf and implemented in Python in the kmodes library: https://github.com/nicodv/kmodes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e062b0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list to hold the variables we will be working with.\n",
    "variables = ['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35129b68",
   "metadata": {},
   "source": [
    "Before getting started, let's take a look at the documentation for KMeans (https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html).\n",
    "\n",
    "**Question 1:** A **hyperparameter** is used to control the learning process and is set prior to fitting the model. What **hyperparameters** can we set for the scikit-learn KMeans model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f418fc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, instantiate a KMeans instance which will fit 3 clusters\n",
    "n_clusters = 3\n",
    "\n",
    "kmeans = KMeans(n_clusters = n_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad9f43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then fit it to the numeric variables of the penguins dataset\n",
    "kmeans.fit(penguins[variables])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623182b7",
   "metadata": {},
   "source": [
    "**Question 2:** What attributes for this model have been set by the `.fit()` method? (Hint: These are attributes whose name ends in an underscore. Hint 2: Make use of Tab in Jupyter to expose the attributes and methods of your fit object. You can also look at the documentation to see what attributes are available and the meanings of them.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ad5ef8",
   "metadata": {},
   "source": [
    "First, take a look at the inertia value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49841c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.inertia_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3087be",
   "metadata": {},
   "source": [
    "**Question 3:** Do we want to minimize or maximize this attribute?\n",
    "\n",
    "**Question 4: True or False** By increasing the number of clusters, we can always decrease the inertia value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff02c14",
   "metadata": {},
   "source": [
    "Now, let's visualize the result of running this algorithm. Notice that we'll make use of the `cluster_centers_` attribute so that we can include the centroids of the clusters in our plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070c89de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the variables you want to visualize.\n",
    "# i and j indicate the index of the variable from the variables list \n",
    "# ['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g']\n",
    "i = 0\n",
    "j = 1\n",
    "\n",
    "plt.figure(figsize = (10,6))\n",
    "sns.scatterplot(data = penguins,\n",
    "               x = variables[i],\n",
    "               y = variables[j],\n",
    "               hue = kmeans.labels_)\n",
    "\n",
    "sns.scatterplot(x = kmeans.cluster_centers_[:,i],\n",
    "                y = kmeans.cluster_centers_[:,j],\n",
    "                s = 500, \n",
    "                hue = list(range(n_clusters)), \n",
    "                marker = 'D',\n",
    "                legend = False);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb44cbad",
   "metadata": {},
   "source": [
    "**Question 5:** Change the values of `i` and `j` in the code above so that you can see different views of the clustering and the centers. For certain combinations of features, your clusters may have quite a bit of overlap. You might even get seemingly disconnected clusters (look at bill_depth_mm and body_mass_g, for example). Why might that be the case? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150e9381",
   "metadata": {},
   "source": [
    "Now, we'll use a Pipeline so that we can scale our variables prior to clustering them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4253ec59",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 3\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    steps = [\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('cluster', KMeans(n_clusters = n_clusters))\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipeline.fit(penguins[variables])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b512178f",
   "metadata": {},
   "source": [
    "Once we have a fit pipeline, we can examine the individual components by referencing then either by index or by name. For example, to see the cluster component, we can use either `pipeline['cluster']` or `pipeline[1]`.\n",
    "\n",
    "With that in mind, look at the inertia value for our multistage model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e735728d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline['cluster'].inertia_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce52620e",
   "metadata": {},
   "source": [
    "**Question 6:** Is it fair to compare the intertia values for the unscaled results to those from the scaled results? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75dbe786",
   "metadata": {},
   "source": [
    "We can now examine the results. Notice that we'll be making use of the `inverse_transform` method of our StandardScaler so that we can transform the cluster centers back into the original units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcc8dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "j = 1\n",
    "\n",
    "plt.figure(figsize = (10,6))\n",
    "sns.scatterplot(data = penguins,\n",
    "               x = variables[i],\n",
    "               y = variables[j],\n",
    "               hue = pipeline[1].labels_)\n",
    "\n",
    "sns.scatterplot(x = pipeline['scaler'].inverse_transform(pipeline['cluster'].cluster_centers_)[:,i],\n",
    "                y = pipeline['scaler'].inverse_transform(pipeline['cluster'].cluster_centers_)[:,j],\n",
    "                s = 500, \n",
    "                hue = list(range(n_clusters)), \n",
    "                marker = 'D',\n",
    "                legend = False);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabf50e9",
   "metadata": {},
   "source": [
    "**Question 7:** What major differences do you see with this clustering compared to the previous one?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d57399",
   "metadata": {},
   "source": [
    "Finally, let's try and find an optimal number of clusters. We'll employ the \"elbow method\" which you saw in DataCamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e901eea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "inertias = []\n",
    "\n",
    "max_clusters = 5\n",
    "for n_clusters in range(1, max_clusters + 1):\n",
    "    \n",
    "    pipeline = Pipeline(\n",
    "        steps = [\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('cluster', KMeans(n_clusters = n_clusters))\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    pipeline.fit(penguins[variables])\n",
    "    \n",
    "    inertias.append(pipeline['cluster'].inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a42110",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,6))\n",
    "plt.plot(range(1, max_clusters + 1), inertias)\n",
    "plt.scatter(range(1, max_clusters + 1), inertias, s = 100);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287ffe9f",
   "metadata": {},
   "source": [
    "**Question 8:** Based on this plot, how many clusters do you think you should use?\n",
    "\n",
    "After you decide the above question, fill in the code below in order to refit the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa33a9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 2\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    steps = [\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('cluster', KMeans(n_clusters = n_clusters))\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipeline.fit(penguins[variables])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c866279e",
   "metadata": {},
   "source": [
    "Finally, use the `pd.crosstab()` function so that you can see how well the clustering distinguishes between penguin species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1695a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(penguins['species'], pipeline['cluster'].labels_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4b32f3",
   "metadata": {},
   "source": [
    "### Bonus Material\n",
    "Do not attempt until you have completed all of the above questions.\n",
    "\n",
    "So far, we have evaluated our clusters using the _intertia_ metric, which is built into the KMeans class. Another commonly used metric for evaluating clusters is the [**silhouette score**](https://en.wikipedia.org/wiki/Silhouette_(clustering)).\n",
    "\n",
    "Scikit-learn offers functions for computing silhouette scores: https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_silhouette_analysis.html."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30de07f4",
   "metadata": {},
   "source": [
    "**Bonus Question 1:** Read the description of the silhouette score on wikipedia (https://en.wikipedia.org/wiki/Silhouette_(clustering)). Do we want to minimize or maximize the silhouette score?\n",
    "\n",
    "**Bonus Question 2:** True or False: We can always increase (or always decrease) the silhouette score by increasing the number of clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6991a4",
   "metadata": {},
   "source": [
    "Let's import the `silhouette_samples` and `silhouette_score` function from the metrics module of scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521ba82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_samples, silhouette_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f605801",
   "metadata": {},
   "source": [
    "Before diving into silhouette scores, let's refit with 3 clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892130c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 3\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    steps = [\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('cluster', KMeans(n_clusters = n_clusters))\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipeline.fit(penguins[variables])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af389465",
   "metadata": {},
   "source": [
    "You can first calculate the silhouette value of each point using the `silhouette_samples` function from scikit-learn's metrics module. Use this function to produce an array of silhouette scores (one per data point). Do you need to use the scaled or the unscaled data for this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9f5265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b20fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette_values = silhouette_samples(pipeline['scaler'].transform(penguins[variables]), pipeline['cluster'].labels_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee552f28",
   "metadata": {},
   "source": [
    "**Question** Look at the distribution of silhouette values (either overall or by cluster). What do you notice? Are they any negative silouette values? If so, how is that possible?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ea7886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f086197",
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette_df = pd.DataFrame({'species': penguins['species'],\n",
    "             'cluster': pipeline['cluster'].labels_,\n",
    "             'silhouette_value': silhouette_values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac44f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette_df.groupby('cluster')['silhouette_value'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56512762",
   "metadata": {},
   "source": [
    "You can also find the silhouette score (the average silhouette value across all datapoints) by using the `silhouette_score` function. Try this out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec506f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8566d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette_avg = silhouette_score(pipeline['scaler'].transform(penguins[variables]), pipeline['cluster'].labels_)\n",
    "\n",
    "silhouette_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31a9d89",
   "metadata": {},
   "source": [
    "**Bonus Coding Task:** Create a for loop which will fit a k-means model over some range of number of clusters. Compare silhouette scores to choose how many clusters to use. How does what you find here compare to what you found using intertia above?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117f4247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e479626",
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette_scores = []\n",
    "\n",
    "max_clusters = 8\n",
    "for n_clusters in range(2, max_clusters + 1):\n",
    "    \n",
    "    pipeline = Pipeline(\n",
    "        steps = [\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('cluster', KMeans(n_clusters = n_clusters))\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    pipeline.fit(penguins[variables])\n",
    "    \n",
    "    silhouette_scores.append(silhouette_score(pipeline['scaler'].transform(penguins[variables]), pipeline['cluster'].labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c20c231",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,6))\n",
    "plt.plot(range(2, max_clusters + 1), silhouette_scores)\n",
    "plt.scatter(range(2, max_clusters + 1), silhouette_scores, s = 100);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e8a38c",
   "metadata": {},
   "source": [
    "**Coding Challenge:** Refit your kmeans model with 3 clusters. Then, manually check the calculations that scikit-learn produces using the definition of the silhouette score.\n",
    "\n",
    "**Hint:** Since this calculation requires computing the distance between all points in your sample, you might find the `pdist` function useful from scipy to quickly do these calculations (https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.pdist.html). You may also want to look at the `squareform` function (https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.squareform.html#scipy.spatial.distance.squareform) to make the output from `pdist` easier to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc3fe7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import pdist, squareform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88ebd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 3\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    steps = [\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('cluster', KMeans(n_clusters = n_clusters))\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipeline.fit(penguins[variables])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959aca43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code For calculating silhouette values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bae67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dists = squareform(pdist(pipeline['scaler'].transform(penguins[variables])))\n",
    "\n",
    "labels = pipeline['cluster'].labels_\n",
    "\n",
    "silhouette_scores = []\n",
    "\n",
    "for pt in range(len(penguins)):\n",
    "    \n",
    "    cluster = labels[pt]\n",
    "\n",
    "    others = [x for x in range(n_clusters) if x != cluster]\n",
    "\n",
    "    a = dists[:, pt][labels == cluster].sum() / ((labels == cluster).sum() - 1)\n",
    "    b = min([dists[:, pt][labels == i].mean() for i in others])\n",
    "\n",
    "    silhouette_scores.append((b - a) / max(a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb53eb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f9fed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette_samples(pipeline['scaler'].transform(penguins[variables]), pipeline['cluster'].labels_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
